<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cybertraining – biology</title><link>/tags/biology/</link><description>Recent content in biology on Cybertraining</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 16 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/biology/index.xml" rel="self" type="application/rss+xml"/><item><title>Report: Report: Aquatic Animals Classification Using AI</title><link>/report/su21-reu-370/project/</link><pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate><guid>/report/su21-reu-370/project/</guid><description>
&lt;p>&lt;a href="https://github.com/cybertraining-dsc/su21-reu-370/actions">&lt;img src="https://github.com/cybertraining-dsc/su21-reu-370/workflows/Check%20Report/badge.svg" alt="Check Report">&lt;/a>
&lt;a href="https://github.com/cybertraining-dsc/su21-reu-370/actions">&lt;img src="https://github.com/cybertraining-dsc/su21-reu-370/workflows/Status/badge.svg" alt="Status">&lt;/a>
Status: final, Type: Report&lt;/p>
&lt;p>Timia Williams, &lt;a href="https://github.com/cybertraining-dsc/su21-reu-370">su21-reu-370&lt;/a>, &lt;a href="https://github.com/cybertraining-dsc/su21-reu-370/blob/main/project/index.md">Edit&lt;/a>&lt;/p>
&lt;div class="pageinfo pageinfo-primary">
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>Marine animals play an important role in the ecosystem. &amp;ldquo;Aquatic animals play an important role in nutrient cycles because they store a large proportion of ecosystem nutrients in their tissues, transport nutrients farther than other aquatic animals and excrete nutrients in dissolved forms that are readily available to primary producers&amp;rdquo; (Vanni MJ 1) Fish images are captured by scuba divers, tourist, or underwater submarines. different angles of fishes image can be very difficult to get because of the constant movement of the fish. In addition to getting the right angles, the images of marine animals are usually low-quality because of the water. Underwater cameras that is required for a good quality image can be expensive. Using AI could potentially increase the marine population by the help of classification by testing the usage of machine learning using the images obtained from the aquarium combined with advanced technology. We collect 164 fish images data from Georgia acquarium to look at the different movements.&lt;/p>
&lt;p>Contents&lt;/p>
&lt;div class="toc">
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#1-introduction">1. Introduction&lt;/a>&lt;/li>
&lt;li>&lt;a href="#2-machine-learning-in-fish-species">2. Machine learning in fish species.&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-datasets">3. Datasets&lt;/a>&lt;/li>
&lt;li>&lt;a href="#31-sample-of-images-of-personal-dataset">3.1. Sample of Images of Personal Dataset&lt;/a>&lt;/li>
&lt;li>&lt;a href="#32-sample-of-images-from-large-scale-fish-dataset">3.2. Sample of Images from Large Scale Fish Dataset&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-conclusion">4. Conclusion&lt;/a>&lt;/li>
&lt;li>&lt;a href="#5-acknowledgments">5. Acknowledgments&lt;/a>&lt;/li>
&lt;li>&lt;a href="#6-references">6. References&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Keywords:&lt;/strong> tensorflow, example.&lt;/p>
&lt;h2 id="1-introduction">1. Introduction&lt;/h2>
&lt;p>It can be challenging to obtain a large number of different complex species in a single aquatic environment. Traditionally, it would take marine biologists years to collect the data and successfully classify the type of species obtained [1]. Scientist says that more than 90 percent of the ocean&amp;rsquo;s species are still undiscovered, with some estimating that there are anywhere between a few hundred thousand and a few million more to be discovered&amp;quot; (National Geographic Society). Currently, scientists know of around 226,000 ocean species. Now and days, Artificial intelligence and machine learning has been used for detection and classification in images. In this project, We will propose to use machine learning techniques to analyze the images obtained from the Georgia Aquarium to identify legal and illegal fishing.&lt;/p>
&lt;h2 id="2-machine-learning-in-fish-species">2. Machine learning in fish species.&lt;/h2>
&lt;p>Aquatic ecologists often count animals to keep up the population count of providing critical conservation and management. Since the creation of underwater cameras and other recording equipment, underwater devices have allowed scientists to safely and efficiently classify fishes images without the disadvantages of manually entering data, ultimately saving lots of time, labor, and money. The use of machine learning to automate image processing has its benefits but has rarely been adopted in aquatic studies. With using efforts to use deep learning methods, the classification of specific species could potentially increase. In fact, there is a study done in Australia&amp;rsquo;s ocean waters that classification of fish through deep learning was more efficient that manual human classification. In the study to test the abundance of different species, &amp;ldquo;The computer’s performance in determining abundance was 7.1% better than human marine experts and 13.4% better than citizen scientists in single image test datasets, and 1.5 and 7.8% higher in video datasets, respectively&amp;rdquo; (Campbell, M. D.). This remarkably explain that using machiene learning in marine animals is a better method than a manually classifying Aquatic animals Not only is it good for classification, it will be used to answer broader questions such as population count, the location of species, its abundance, and how it appears to be thriving. Since Machine learning and deep learning are often defined as one, both learning methods will be used to analyze the images and find patterns on my data.&lt;/p>
&lt;h2 id="3-datasets">3. Datasets&lt;/h2>
&lt;p>We used two datasets in my project. The first dataset includes the pictures that I took at the Georgia Acquarium. That dataset was used for testing. The second dataset used was a fish dataset from kaggle which contains 9 different seafood types (Black Sea Sprat, Gilt-Head Bream, Hourse Mackerel, Red Mullet, Red Sea Bream, Sea Bass, Shrimp, Striped Red Mullet, Trout). For each type, there are 1000 augmented images and their pair-wise augmented ground truths.&lt;/p>
&lt;p>The link to access the Kaggle dataset is &lt;a href="https://www.kaggle.com/crowww/a-large-scale-fish-dataset">https://www.kaggle.com/crowww/a-large-scale-fish-dataset&lt;/a>&lt;/p>
&lt;h2 id="31-sample-of-images-of-personal-dataset">3.1. Sample of Images of Personal Dataset&lt;/h2>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/su21-reu-370/raw/main/project/images/IMG_1566.jpg" width="30%"> &lt;img src="https://github.com/cybertraining-dsc/su21-reu-370/raw/main/project/images/IMG_1583.jpg" width="30%"> &lt;img src="https://github.com/cybertraining-dsc/su21-reu-370/raw/main/project/images/IMG_1574.jpg" width="30%">&lt;/p>
&lt;p>Left to right: Banded Archerfish, Lionfish, and Red Piranha&lt;/p>
&lt;p>&lt;strong>Figure 1:&lt;/strong> These images are samples of my personal data which is made up of images of fishes taken at the Georgia Acquarium.&lt;/p>
&lt;h2 id="32-sample-of-images-from-large-scale-fish-dataset">3.2. Sample of Images from Large Scale Fish Dataset&lt;/h2>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/su21-reu-370/raw/main/project/images/IMG_1565.jpg" alt="Figure 1">&lt;/p>
&lt;h2 id="4-conclusion">4. Conclusion&lt;/h2>
&lt;p>Deep learning methods provide a faster, cheaper, and more accurate alternative to manual data analysis methods currently used to monitor and assess animal abundance and have much to offer the field of aquatic ecology. We was able to create a model to prove that we can use AI to efficiently detect and classify marine animals.&lt;/p>
&lt;h2 id="5-acknowledgments">5. Acknowledgments&lt;/h2>
&lt;p>Special thanks to these people that helped me with this paper:
Gregor von Laszewski
Yohn Jairo
Carlos Theran
Jacques Fleischer
Victor Adankai&lt;/p>
&lt;h2 id="6-references">6. References&lt;/h2></description></item><item><title>Report: Project: Structural Protein Sequences Classification</title><link>/report/sp21-599-357/project/</link><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate><guid>/report/sp21-599-357/project/</guid><description>
&lt;p>&lt;a href="https://github.com/cybertraining-dsc/sp21-599-357/actions">&lt;img src="https://github.com/cybertraining-dsc/sp21-599-357/workflows/Check%20Report/badge.svg" alt="Check Report">&lt;/a>
&lt;a href="https://github.com/cybertraining-dsc/sp21-599-357/actions">&lt;img src="https://github.com/cybertraining-dsc/sp21-599-357/workflows/Status/badge.svg" alt="Status">&lt;/a>
Status: final, Type: Project&lt;/p>
&lt;p>Jiayu Li, &lt;a href="https://github.com/cybertraining-dsc/sp21-599-357/">sp21-599-357&lt;/a>, &lt;a href="https://github.com/cybertraining-dsc/sp21-599-357/blob/main/project/index.md">Edit&lt;/a>&lt;/p>
&lt;ul>
&lt;li>Code:
&lt;ul>
&lt;li>&lt;a href="https://github.com/cybertraining-dsc/sp21-599-357/blob/main/project/code/benchmark.py">benchmark.py&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/cybertraining-dsc/sp21-599-357/blob/main/project/code/lstm.ipynb">lstm.ipynb&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="pageinfo pageinfo-primary">
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>The goal of this project is to predict the family of a protein based on the amino acid sequence of the protein.
The structure and function of a protein are determined by the amino acid sequence that composes it.
In the protein structure data set, each protein is classified according to its function. Categories include: HYDROLASE, OXYGEN TRANSPORT, VIRUS, SIGNALING PROTEIN, etc. dozens of kinds. In this project, we will use nucleic acid sequences to predict the type of protein.&lt;/p>
&lt;p>Although there are already protein search engines such as BLAST[^1] that can directly query the known protein families. But for unknown proteins, it is still important to use deep learning algorithms to predict their functions.&lt;/p>
&lt;p>Protein classification is a simpler problem than protein structure prediction[^7]. The latter requires the complete spatial structure of the protein, and the required deep learning model is extremely complex.&lt;/p>
&lt;p>Contents&lt;/p>
&lt;div class="toc">
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#1-introduction">1. Introduction&lt;/a>&lt;/li>
&lt;li>&lt;a href="#2-dataset">2. Dataset&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-deep-learning-algorithm">3. Deep learning algorithm&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#31-word-embedding">3.1 Word Embedding&lt;/a>&lt;/li>
&lt;li>&lt;a href="#32-lstm">3.2 LSTM&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#4-benchmark">4. Benchmark&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#41-compare-with-test-benchmark">4.1 Compare with test benchmark&lt;/a>&lt;/li>
&lt;li>&lt;a href="#42-the-impact-of-the-number-of-labels-on-accuracy">4.2 The impact of the number of labels on accuracy&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#5-conclusion">5. Conclusion&lt;/a>&lt;/li>
&lt;li>&lt;a href="#6-acknowledgments">6. Acknowledgments&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-references">7. References&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Keywords:&lt;/strong> Protein Sequences, Deep learning&lt;/p>
&lt;h2 id="1-introduction">1. Introduction&lt;/h2>
&lt;p>The structure and function of a protein are determined by the amino acid sequence that composes it. The amino acid sequence can be regarded as a language composed of 4 different characters. In recent years, due to the development of deep learning, the ability of deep neural networks to process natural language has reached or even surpassed humans in some areas. In this project, we tried to treat the amino acid sequence as a language and use the existing deep learning model to analyze it to achieve the purpose of inferring its function.&lt;/p>
&lt;p>The data sets used in the project come from Research Collaboratory for Structural Bioinformatics (RCSB) and Protein Data Bank (PDB)&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>The data set contains approximately 400,000 amino acid sequences and has been labeled. The label is the family to which the protein belongs. The protein family includes HYDROLASE, HYDROLASE/HYDROLASE INHIBITOR, IMMUNE SYSTEM, LYASE, OXIDOREDUCTASE, etc. Therefore this problem can be regarded as a classification problem. The input of the model is a sequence, the length of the sequence is uncertain, and the output of the model is one of several categories.
By comparing DNN, CNN, LSTM and other common models, we have achieved effective prediction of protein energy supply.&lt;/p>
&lt;h2 id="2-dataset">2. Dataset&lt;/h2>
&lt;p>PDB is a data set dedicated to the three-dimensional structure of proteins and nucleic acids. It has a very long history, dating back to 1971. In 2003, PDB developed into an international organization wwPDB. Other members of wwPDB, including PDBe (Europe), RCSB (United States), and PDBj (Japan) also provide PDB with a center for data accumulation, processing and release. Although PDB data is submitted by scientists from all over the world, each piece of data submitted will be reviewed and annotated by wwPDB staff, and whether the data is reasonable or not. The PDB and the software it provides are now free and open to the public.
In the past few decades, the number of PDB structures has grown at an exponential rate.&lt;/p>
&lt;p>Structural biologists around the world use methods such as X-ray crystallography, NMR spectroscopy, and cryo-electron microscopy to determine the position of each atom relative to each other in the molecule. Then they will submit this structural information, wwPDB will annotate it and publish it to the database publicly.&lt;/p>
&lt;p>PDB supports searching for ribosomes, oncogenes, drug targets, and even the structure of the entire virus. However, the number of structures archived in the PDB is huge, and finding the information may be a difficult task.&lt;/p>
&lt;p>The information in the PDB data set mainly includes: protein/nucleic acid source, protein/nucleic acid molecule composition, atomic coordinates, experimental methods used to determine the structure.
Structural Protein Sequences Dataset: &lt;a href="https://www.kaggle.com/shahir/protein-data-set/code">https://www.kaggle.com/shahir/protein-data-set/code&lt;/a>&lt;/p>
&lt;p>Protein dataset classification: &lt;a href="https://www.kaggle.com/rafay12/anti-freeze-protein-classification">https://www.kaggle.com/rafay12/anti-freeze-protein-classification&lt;/a>&lt;/p>
&lt;p>RCSB PDB: &lt;a href="https://www.rcsb.org/">https://www.rcsb.org/&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/sp21-599-357/main/project/images/fig4.png" alt="Figure 1">&lt;/p>
&lt;p>&lt;strong>Figure 1:&lt;/strong> Data set sample.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/sp21-599-357/main/project/images/fig1.png" alt="Figure 2">&lt;/p>
&lt;p>&lt;strong>Figure 2:&lt;/strong> The frequency of appearance of different labels.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/sp21-599-357/main/project/images/fig2.png" alt="Figure 3">&lt;/p>
&lt;p>&lt;strong>Figure 3:&lt;/strong> The length distribution of amino acid sequences.&lt;/p>
&lt;h2 id="3-deep-learning-algorithm">3. Deep learning algorithm&lt;/h2>
&lt;p>Two deep learning models, CNN and LSTM&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, are mainly used in this project. In addition, the Word Embedding algorithm is also used to preprocess the data.&lt;/p>
&lt;p>Among these models, the CNN model comes from the Kaggle website&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> and will be used as a test benchmark. We will try to build a simpler but more accurate model with an accuracy rate of at least not lower than the test benchmark.&lt;/p>
&lt;h3 id="31-word-embedding">3.1 Word Embedding&lt;/h3>
&lt;p>A word embedding is a class of approaches for representing words and documents using a dense vector representation.&lt;/p>
&lt;p>Iin an embedding, words are represented by dense vectors where a vector represents the projection of the word into a continuous vector space.&lt;/p>
&lt;p>The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used.&lt;/p>
&lt;p>The position of a word in the learned vector space is referred to as its embedding.&lt;/p>
&lt;p>Two popular examples of methods of learning word embeddings from text include: Word2Vec&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> and GloVe&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/sp21-599-357/main/project/images/embed.png" alt="Figure 4">&lt;/p>
&lt;p>&lt;strong>Figure 4:&lt;/strong> Word2Vec and GloVe.&lt;/p>
&lt;h3 id="32-lstm">3.2 LSTM&lt;/h3>
&lt;p>Recurrent Neural Network (RNN) is a neural network used to process sequence data. Compared with the general neural network, it can process the data of sequence changes. For example, the meaning of a word will have different meanings because of the different content mentioned above, and RNN can solve this kind of problem well.&lt;/p>
&lt;p>Long short-term memory (LSTM) is a special kind of RNN, mainly to solve the problem of gradient disappearance and gradient explosion during long sequence training. Compared to ordinary RNN, LSTM can perform better in longer sequences.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/sp21-599-357/main/project/images/fig3.png" alt="Figure 5">&lt;/p>
&lt;p>&lt;strong>Figure 5:&lt;/strong> LSTM.&lt;/p>
&lt;h2 id="4-benchmark">4. Benchmark&lt;/h2>
&lt;h3 id="41-compare-with-test-benchmark">4.1 Compare with test benchmark&lt;/h3>
&lt;p>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> is a highly accurate model on the Kaggle website. It is currently one of the models with the highest accuracy on this data set.
In this project, CNN model in &lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> will be used as a test benchmark. We use categorical cross entropy as loss function.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Model&lt;/th>
&lt;th>CNN&lt;/th>
&lt;th>LSTM&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>#parameters&lt;/td>
&lt;td>273,082&lt;/td>
&lt;td>&lt;strong>203,226&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Accuracy&lt;/td>
&lt;td>91.6%&lt;/td>
&lt;td>&lt;strong>91.9%&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Training time&lt;/td>
&lt;td>7ms/step&lt;/td>
&lt;td>58ms/step&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Batch size&lt;/td>
&lt;td>128&lt;/td>
&lt;td>256&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Loss&lt;/td>
&lt;td>0.4051&lt;/td>
&lt;td>&lt;strong>0.3292&lt;/strong>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Both the CNN model and the LSTM model use the word embedding layer for data dimensionality reduction. After testing, the result is that LSTM uses fewer parameters to achieve the same or even slightly higher accuracy than the benchmark. However, due to the relatively complex structure of LSTM, its training speed and guessing speed are slower.&lt;/p>
&lt;p>In order to make a fair comparison with the test benchmark, we only selected the 10 most frequent samples as the data set, which is also the original author&amp;rsquo;s choice. Therefore, the accuracy of more than 90% here is only of relative significance, and does not mean that the same accuracy can be achieved in practical applications (the data set usually has more categories).&lt;/p>
&lt;h3 id="42-the-impact-of-the-number-of-labels-on-accuracy">4.2 The impact of the number of labels on accuracy&lt;/h3>
&lt;p>In order to further test the performance of LSTM on different data sets, we further increased the number of labels, gradually increasing from 10 labels to 20 labels. Figure 6 shows the effect of the number of labels on accuracy.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/sp21-599-357/main/project/images/AccuracyandLoss.png" alt="Figure 6">&lt;/p>
&lt;p>&lt;strong>Figure 6:&lt;/strong> The impact of the number of labels on accuracy.&lt;/p>
&lt;p>Note that due to the limitation of the data set, the number of samples belonging to different labels is different. If we want to balance different categories, we have to shrink the data set, which will affect the accuracy. This is one of the limitations of this test.&lt;/p>
&lt;h2 id="5-conclusion">5. Conclusion&lt;/h2>
&lt;p>The deep learning model gives a prediction accuracy of more than 90% for the 10 most common protein types. If the number of label is increased to 20, the accuracy rate will drop to 80%.
The traditional machine learning model is difficult to deal with string data of different lengths.&lt;/p>
&lt;h2 id="6-acknowledgments">6. Acknowledgments&lt;/h2>
&lt;p>The author would like to thank Dr. Gregor von Laszewski for his invaluable feedback on this paper, and Dr. Geoffrey Fox for sharing his expertise in Big Data applications throughout this course.&lt;/p>
&lt;h2 id="7-references">7. References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Sussman, Joel L., et al. &amp;ldquo;Protein Data Bank (PDB): database of three-dimensional structural information of biological macromolecules.&amp;rdquo; Acta Crystallographica Section D: Biological Crystallography 54.6 (1998): 1078-1084.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Sundermeyer, Martin, Ralf Schlüter, and Hermann Ney. &amp;ldquo;LSTM neural networks for language modeling.&amp;rdquo; Thirteenth annual conference of the international speech communication association. 2012.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Kaggle, Protein Sequence Classification. &lt;a href="https://www.kaggle.com/helmehelmuto/cnn-keras-and-innvestigate">https://www.kaggle.com/helmehelmuto/cnn-keras-and-innvestigate&lt;/a>&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Church, Kenneth Ward. &amp;ldquo;Word2Vec.&amp;rdquo; Natural Language Engineering 23.1 (2017): 155-162.&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. &amp;ldquo;Glove: Global vectors for word representation.&amp;rdquo; Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014.&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item></channel></rss>