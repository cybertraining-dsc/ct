<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cybertraining – environment</title><link>/tags/environment/</link><description>Recent content in environment on Cybertraining</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Mon, 15 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/environment/index.xml" rel="self" type="application/rss+xml"/><item><title>Report: Aquatic Toxicity Analysis with the aid of Autonomous Surface Vehicle (ASV)</title><link>/report/fa20-523-312/project/project/</link><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate><guid>/report/fa20-523-312/project/project/</guid><description>
&lt;p>&lt;a href="https://github.com/cybertraining-dsc/fa20-523-312/actions">&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/workflows/Check%20Report/badge.svg" alt="Check Report">&lt;/a>
&lt;a href="https://github.com/cybertraining-dsc/fa20-523-312/actions">&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/workflows/Status/badge.svg" alt="Status">&lt;/a>
Status: final, Type: Project&lt;/p>
&lt;p>Saptarshi Sinha, &lt;a href="https://github.com/cybertraining-dsc/fa20-523-312/">fa20-523-312&lt;/a>, &lt;a href="https://github.com/cybertraining-dsc/fa20-523-312/blob/main/project/project.md">Edit&lt;/a>&lt;/p>
&lt;div class="pageinfo pageinfo-primary">
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>With the passage of time, human activities
have created and contributed much to the aggrandizing problems of various forms of environmental pollution. Massive amounts of industrial effluents and agricultural waste wash-offs, that often comprise pesticides and other forms of agricultural chemicals, find their way to fresh water bodies, to lakes, and eventually to the oceanic systems. Such events start producing a gradual increase in the toxicity levels of marine ecosystems thereby perturbing the natural balance of such water-bodies. In this endeavor, an attempt will be made to analyze the various water quality metrics (viz. temperature, pH, dissolved-oxygen level, and conductivity) that are measured with the help of autonomous surface vehicles (ASV). The collected data will undergo big data analysis tasks so as to find the general trend of values for the water quality of the given region. These obtained values will then be compared with sample water quality values obtained from neighboring sources of water for ascertaining if these sample values exhibit aberration from the established values that were found earlier from the big data analysis tasks for water-quality standards. In the event, the sample data popints significantly deviate from the standard values established earlier, it can then be successfully concluded that the aquatic system in question, from which the water sample was sourced from, has been degraded and may no longer be utilized for any form of human usage, such as being used for drinking water purposes.&lt;/p>
&lt;p>Contents&lt;/p>
&lt;div class="toc">
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#1-introduction">1. Introduction&lt;/a>&lt;/li>
&lt;li>&lt;a href="#2-background-research-and-previous-work">2. Background Research and Previous Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-choice-of-data-sets">3. Choice of Data-sets&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-methodology">4. Methodology&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#41-hardware-component">4.1 Hardware Component&lt;/a>&lt;/li>
&lt;li>&lt;a href="#42-software-component">4.2 Software Component&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#421-data-pre-processing">4.2.1 Data Pre-processing&lt;/a>&lt;/li>
&lt;li>&lt;a href="#422-attributes-of-the-preliminary-data">4.2.2 Attributes of the preliminary data&lt;/a>&lt;/li>
&lt;li>&lt;a href="#423-unsupervised-learning-k-means-clustering-analysis-safe--unsafe-centroid-calculation">4.2.3 Unsupervised learning: K-means clustering analysis (&amp;ldquo;Safe&amp;rdquo; &amp;amp; &amp;ldquo;Unsafe&amp;rdquo; Centroid calculation)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#424-display-of-results--analysis-of-any-given-sample-values-set">4.2.4 Display of results &amp;amp; analysis of any given sample values set&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#5-inference">5. Inference&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#51-analysis-of-extracted-data-and-statistical-information">5.1 Analysis of extracted data and statistical information&lt;/a>&lt;/li>
&lt;li>&lt;a href="#52-centroids--predicted-classesclusters">5.2 Centroids &amp;amp; Predicted Classes/Clusters&lt;/a>&lt;/li>
&lt;li>&lt;a href="#53-heatmaps-for-the-years---2017-2018-2019-and-2020">5.3 Heatmaps for the years - 2017, 2018, 2019, and 2020&lt;/a>&lt;/li>
&lt;li>&lt;a href="#54-analysis-of-sample-set-of-values">5.4 Analysis of sample set of values&lt;/a>&lt;/li>
&lt;li>&lt;a href="#55-benchmark-information">5.5 Benchmark information&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#6-conclusion">6. Conclusion&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-acknowledgements">7. Acknowledgements&lt;/a>&lt;/li>
&lt;li>&lt;a href="#8-references">8. References&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Keywords:&lt;/strong> toxicology, pollution, autonomous systems, surface vehicle, sensors, arduino, water quality, data analysis, environment, big data, ecosystem&lt;/p>
&lt;h2 id="1-introduction">1. Introduction&lt;/h2>
&lt;p>When it comes to revolutionizing our qualities of life and improving standards, there is not another branch of science and technology that has made more impact than the myriad technological capabilities offered by the areas of Artificial Intelligence (AI) and its sub-fields involving Computer Vision, Robotics, Machine Learning, Deep Learning, Reinforcement Learning, etc. It should be borne in mind that AI was developed to allow machines/computer processors to work in the same way as the human brain works and which could make intelligent decisions at every conscious level. It was meant to help with tasks for rendering scientific applications more smarter and efficient. There are many tasks that can be performed in a far more dexterous fashion by employing smart-machines and algorithms than by involving human beings. But even more importantly, AI has also been designed to perform tasks that cannot be successfully completed by employing human beings. This could either be due to the prolonged boredom of the task itself, or a task that involves hazardous environments that cannot sustain life-forms for a long time. Some examples in this regard would involve exploring deep mines or volcanic trenches for mineral deposits, exploring the vast expanse of the universe and heavenly bodies, etc. And this is where the concept employing AI/Robotics based technology fits in perfectly for aquatic monitoring and oceanographical surveillance based applications.&lt;/p>
&lt;p>Toxicity analysis of ecologically vulnerable water-bodies, or any other marine ecosystem for that matter, could give us a treasure trove of information regarding biodiversity, mineral deposits, unknown biophysical phenomenon, but most importantly, it could also provide meaningful and scientific information related to the degradation of the ecosystem itself. In this research endeavor, an attempt will be made to utilize aquatic Autonomous Surface Vehicle (ASV) that will be deployed in marine ecosystems and which can continue collecting data for a prolonged period of time. Such vehicles are typically embedded with different kinds of electronic sensors, that are capable of measuring physical quantities such as temperature, pH, specific conductance, dissolved oxygen level, etc. The data collected by such a system can either be over a period of time (temporal data), or it could cover a vast aquatic geographical region (spatial data). This is the procedure by which environmental organizations record and store massive amounts of data that can be analyzed to obtain useful information about the particular water body in question. Such analytical work will provide us with statistical results that can then be compared with existing sample values so as to decipher whether the water source, from where the sample was obtained, manifests normal trend of values or shows large deviations from established trends that can signify an anomaly or biodegradation of the ecosystem. The datasets used in this endeavor are provided publicly by environmental organizations in the United States, such as the US Geological Survey (USGS). While the primary goal involves conducting big data analysis tasks for the databases so as to obtain useful statistical results, a secondary goal in this project involves finding out the extent to which a particular sample of water, obtained from a specific source of water, deviates from the normal trend of values. The extent of such deviations can then give us an indication about the status of the aquatic degradation of the ecosystem in question. The data analysis framework will be made as robust as possible and in this effort, we will work with data values that are spread over multiple years and not just focused on a single year.&lt;/p>
&lt;h2 id="2-background-research-and-previous-work">2. Background Research and Previous Work&lt;/h2>
&lt;p>After reviewing the necessary background literature and previous work that has been done in this field, it can be stated that most of such endeavors focused majorly on environmental data collection with the help of sensors attached to a navigational buoy in a particular location of a water-body. Such works did not involve any significant data analysis framework and focused on particular niche areas. For instance, a particular research effort involved deploying a surface vehicle that collected data from large swaths of geographical areas in various water bodies but concentrated primarily on different algorithms employed for vehicular navigation and their relative success rates &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. Other research attempts focussed on even more niche areas such as study of the migration pattern exhibited by zooplanktons upon natural and aritifical irradiance &lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, and detection and monitoring of marine fauna &lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>. Although these are interesting projects and can provide us with novel information about various aspects of biological and aquatic research, such research attempts neither focused much on the data analysis portion for multiple sensory inputs (viz. temperature, pH, specific conductance, and dissolved oxygen level, which are the four most important water quality parameters) nor did they involve an intricate procedure to compare the data with sample observations so as to arrive at a suitable conclusion regarding the extent of environmental degradation of a particular water body.&lt;/p>
&lt;p>As mentioned in the previous section, this research endeavor will exhaustively focus not just on the working principles and deployment of surface vehicles to collect data, but it will also involve employing deeper study towards the subject of big-data analysis of both the current data of the system in question and the past data obtained for the same aquatic profile. In this way, it would be possible to learn more about the toxicological aspects of the ecosystem in question and which can then be also applied to neighboring regions.&lt;/p>
&lt;h2 id="3-choice-of-data-sets">3. Choice of Data-sets&lt;/h2>
&lt;p>Upon exploring a wide array of available datasets, the following two data repositories were given consideration to get the required water quality based data over a particular period of time and for a particular geographical region:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://waterdata.usgs.gov/nwis/qw">USGS Water Quality Data&lt;/a> &lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;a href="https://www.epa.gov/waterdata/water-quality-data-download">EPA Water Quality Data&lt;/a> &lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>&lt;/li>
&lt;/ol>
&lt;p>After going through the sample data values than can be visualized from the respective websites of USGS and EPA, the USGS datasets were chosen over the EPA datasets. This is mainly because the USGS datasets are more commensurate with the research goal of this endeavor, especially since it contains a huge array of databases that focuses on the four most important water quality data which are - temperature, pH, specific conductance, and dissolved oxygen level. Some previous work was conducted on similar USGS datasets by a particular research team &lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>. However, such work was drastically different in nature, when compared with this research attempt, since its emphasis was on a very broad perspective so as to create an overview of how to use and visualize the data from the USGS water quality portal. Besides, such work emphasizes on characterizing the seasonal variation of lake water clarity in different regions throughout the continental US, something that is very deviant from what would be addressed in this particular article which majorly involves studying environmental degradation and aquatic toxicology from the context of big data analytical tasks.&lt;/p>
&lt;p>To address the questions involving existence of multiple data-sets and motivation of using multiple data-sets, we must keep in mind that the very nature of this study is based on historical trends of the nature of water-quality in a particular region from the past and to this effect, emphasis has been given to use data values from the past years as well in addition to the current year. The geographical location for this analysis was chosen to be the East Fork Whitewater River that is located at Richmond, IN (USA). The years that have been chosen in this case are 2017, 2018, 2019, and 2020. For all these years, focus would be placed on the same time-period, that spans from November 1 to November 14, for all these years so as to establish consistency and high fidelity across the borad. Having multiple data-sets in this way will help us in achieving robust data-analytical results. It would also ensure that too much focus is not given on outlier cases, that may be relevant to just a particular time and day on a given year, or an aberration in the data that may only have surfaced due to an unknown underlying phenomenon or some form of cataclysmic event from the past. Using multiple datasets would help to get a resultant data structure that is more likely to converge towards an approximate level of historical thresholds and which can then be used to find out how a current sample data-point deviates from such established trends of previous patterns.&lt;/p>
&lt;h2 id="4-methodology">4. Methodology&lt;/h2>
&lt;h3 id="41-hardware-component">4.1 Hardware Component&lt;/h3>
&lt;p>Although this project focuses more on the data analysis portion than mechanical details, some information relating to the design and working principle of ASVs is provided herewith.The rough outline of an autonomous surface vehicle (ASV) in question has been perceived in Autodesk Fusion 360, which is a software package that helps creating and printing three-dimensional custom designs. A preliminary model has been designed in this software and after printing, it can be interfaced with the appropriate sensors in question. The system can be driven by an Arduino-Uno based microcontroller or even a Raspberry Pi based microprocessor, and it can comprise different types of environmental sensors that helps with collecting and offloading data to remote servers/machines. Some of these sensors can be purchased commercially from the vendor, &amp;ldquo;Atlas Scientific&amp;rdquo; &lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>. For instance, the following sensors can be used with an ASV to measure the four most important water quality parameters involving temperature, pH, dissolved oxygen level, and specific conductance values:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://atlas-scientific.com/kits/pt-1000-temperature-kit/">PT-1000 Temperature sensor kit&lt;/a> &lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;a href="https://atlas-scientific.com/kits/ph-kit/">Potential of Hydrogen (pH) sensor kit&lt;/a> &lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;a href="https://atlas-scientific.com/kits/dissolved-oxygen-kit/">Dissolved Oxygen (DO) sensor kit&lt;/a> &lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;a href="https://atlas-scientific.com/kits/conductivity-k-1-0-kit/">Conductivity K 1.0 sensor kit&lt;/a> &lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>&lt;/li>
&lt;/ul>
&lt;p>A very rudimentary framework of such a system has been realized in the Autodesk Fusion 360 software architecture as shown below. A two-hull framework is usually more helpful than a single hull based design since the former would help with stability issues especially while navigating through choppy waters. Figure 1 shows the design in the form of a very simplistic platform but which definitely lays down the foundation for a more complex structure for an ASV system.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/asvdesign.png" alt="ASV from Fusion 360">&lt;/p>
&lt;p>&lt;strong>Figure 1:&lt;/strong> Nascent framework of an ASV system in Fusion 360&lt;/p>
&lt;p>With the chassis framework out of the way, a careful analysis could be conducted towards the other successful components of such a vehicle so as to complete the entire build process for a fully functional prototype ASV. In essence, an ASV can be thought of being composed of certain key sub-elements. From a broad perspective, they comprise the hardware makeup, a suitable propulsion system, a sensing system, a communication system, and an appropriate source of onboard power source. The hardware makeup being out of the way, the other aspects can now be elaborated as follows:&lt;/p>
&lt;p>&lt;strong>Propulsion System:&lt;/strong> Primarily, the two major possibilities for propulsion systems in an ASV involve using either a single servo motor with an assortment of rudders and propellers for appropriate steering, or using two separate servo motors, one of which will drive the left-hand side of the system and the other would drive the right-hand side. The second arrangement is preferred in many scenarios as it provides with better maneuverability and control of the system as a whole. For instance, to move forward in a rectilinear fashion, both the motors would be given the same level of power. Whereas for steering the system in a particular direction, one of the motors would be assigned a lower power level than the other, thereby enabling the system to curve inwards on the side which has the motor with a lower power level. Of course, there will always be perturbations and natural disturbances that will deter the system from making these correct path changes. For this reason, a Proportional-Integral-Derivative (PID) controlled response could be augmented with the locomotion algorithms.&lt;/p>
&lt;p>&lt;strong>Sensing System:&lt;/strong> An ASV can have as many sensors as possible (dependent upon physical and electrical constraints of microcontroller/microprocessor) but for a study like this, an arrangement involving four different sensors needs to be integrated in the ASV which measures the four principle water quality parameters. This way, when the entire ASV system is deployed in an aquatic environment, it will be able to simultaneously provide readings for all four water-quality parameters in this case. Precisely, these water-quality parameters would be temperature, potential of hydrogen (pH), dissolved oxygen level, and specific conductance value. It should be noted in this perspective that it is possible to include even more sensors in this ASV system. However, the reason why it is generally not helpful to go beyond a certain number of sensors is primarily because of two reasons. Firstly, these parameters are important to most toxicological analysis studies &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, and the readings provided by such a sensory system could be considered as a foundation which could provide future directions (including adding more sensors, if needed). Secondly, we should also keep in mind that the hardware system has certain constraints. In this scenario, it involves a sensory shield (that can be integrated with a microcontroller or microprocessor) which can be used for incorporating multiple sensors. But it also has a maximum of four ports for four different sensors only. Though it is possible to add multiple layers of shield on top of the others (thereby raising the capability of integrating the number of sensors to eight or even more), it leads to unnecessary bandwidth issues, memory depletion possibilities, along with an increased demand of higher power supply. These issues will especially be more consequential if we are dealing with a microcontroller that has very limited memory and power, unlike a microprocessor. Hence, the decision to stick with only a certain number of sensors is really an important one.&lt;/p>
&lt;p>&lt;strong>Communication System:&lt;/strong> This is possibly the most important part of the ASV system as we need to device a technique to offload the data that is collected by the vehicle back to a remote computer/server that would likely be located at a considerable distance away from the ASV. There are different options that can be considered in this regard for establishing a proper communicative functionality between the ASV and the remote computer. Some options that are typically considered involve Bluetooth, IR signals, RF signals, GPS-based system, satellite communication, etc. There are both pros and cons when it comes to using any of these different communication systems for the ASV. However, the most important metric in this case involves the maximum range the communication system could span over. Obviously, some of the options (viz. Bluetooth) would not be possible in this regard as they have a very limited communication range. Some others (viz. satellite communication systems) have a very high range but are nevertheless not feasible for small-scale research endeavors as they require too much onboard processing power to even carry out their most basic operations. Hence, a balanced approach is normally followed in these scenarios and a GPS/RF-based system is often found to be a reliable candidate for carrying out the proposed tasks of an ASV.&lt;/p>
&lt;p>&lt;strong>Power Source:&lt;/strong> Finally, we certainly need an onboard processing power system that can provide the required amount of power to all the functional entities housed in the ASV system. The characteristic of such a desired power source would be that it would not require frequent charging and can sustain proper ASV operations for at least five to six hours. Additionally, the weight of the power source should also not be too clumsy that might put the stability of the entire ASV system in jeopardy. It must have a suitable weight, and should also come in an appropriate shape and size such that the weight of the entire power module is evenly distributed over a large area, thereby further reinforcing the stability of the system.&lt;/p>
&lt;h3 id="42-software-component">4.2 Software Component&lt;/h3>
&lt;p>With the help of the collected data from ASVs, the datasets of USGS are then prepared which meticulously tabulates all the readings from the different water sensors of the ASV. Such tabular data is made public for research and other educational purposes. In this endeavor, such datasets will be analyzed to decipher the median convergent values of the water body for the four different parameters that have been measured (i.e. temperature, pH, dissolved oxygen level, and specific conductance). The results of this data analysis task will manifest the water quality parametric values and standards for the particular aquatic ecosystem. Such a result will then be used to find out if a different water sample value sourced from a particular region deviates by a large proportion from the established standards which was obtained after analyzing the historical data from USGS for a regional source of water. The USGS website makes it easier to find data from a nearby geographical region by making it possible to enter the desired location prior to searching for water quality data in their huge databases. In this way, one can also use these databases to figure out if the water quality parameters of the particular ecological system varies wildly from a neighboring system that has almost the same geographical and ecological attributes.&lt;/p>
&lt;p>The establishment of the degree of variance of the sample data from the normal standards will be carried out by deciphering the number of water quality paramteric values that are aberrant in nature. For instance, a sample value with only an aberrant pH value could be classified as &amp;ldquo;Critical Category 1&amp;rdquo; whereas, a sample value with aberrant values for pH, temperature, and specific conductance would be classified as &amp;ldquo;Critical Category 3&amp;rdquo;. The aberrant nature of a particular parameter is postulated by enumerating how far the values are away from the established median data, which was obtained from the past/historical datasets. This will involve centroid-based calculations for the k-means algorithm (discussed in the next section). Such aberrant nature of a particular water quality paramteric value can also be figured out by using the context of standard deviations and quartile ranges. For instance, if the current data resides in the second quartile, it can be demarcated as being more or less consistent with previously established values. However, if it resides in the first or third quartile then it might be that the particular ecosystem has aberrant aspects, which would then need to be investigated for possible effects of outside pollutants (viz. industrial effluents, agricultural wash-off, etc.), or presence of harmful invasive species that might be altering the delicate natural balance of the ecosystem in question.&lt;/p>
&lt;p>The software logic is located at this &lt;a href="https://github.com/cybertraining-dsc/fa20-523-312/blob/main/project/code/toxicologyASV.ipynb">link&lt;/a> &lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup>. It has been created using the aid of Google Colaboratory platform, or simply Colab &lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>. The code has been appropriately commented and documented in such a way that it can be easily reproduced. Important instructions and vital information about different aspects of the code have been properly written down wherever necessary. The coding framework helps in corroborating the inferences and conclusions made by this research attempt, and which are described in detail in the subsequent sections. The major steps that have been followed in establishing the software logic for this big-data analytical task are discussed below.&lt;/p>
&lt;h4 id="421-data-pre-processing">4.2.1 Data Pre-processing&lt;/h4>
&lt;p>&lt;strong>Meta-data&lt;/strong>: As with any other instance of big data, the data obtained from the USGS website is rife with many unnecessary information. Most of these information relate to meta-data for the particular database and it also contains detailed logistical information such as location information, units used for measurement, contact information, etc. Fortunately, all these information have been bunched up nicely at the beginning of the database and they were conveniently filtered out by skipping the first thirty-four (34) rows while reading the corresponding comma separated value (csv) files.&lt;/p>
&lt;p>&lt;strong>Extraction of required water-quality parameters (Temperature, Specific Conductance, pH, Dissolved Oxygen)&lt;/strong>: After filtering out the meta-data, it is very essential to focus only on the relevant portion of the database which contains the required information that is needed for the data analysis tasks. In this case, if we observe carefully, we will notice that not all the columns contain the required information relating to water-quality parameters. Some of them include information such as date, time, system&amp;rsquo;s unit, etc. Since these will not be required for our analysis task, we extract only those columns that contain information relating to the four primary water-quality parameters. Figure 2 displays the layout of the USGS dataset files containing all the extraneous information that are deemed unnecessary for the big data analysis task.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/sampledatabase.png" alt="database sample">&lt;/p>
&lt;p>&lt;strong>Figure 2:&lt;/strong> Sample Database file obtained from the USGS water-quality database for the year 2017&lt;/p>
&lt;h4 id="422-attributes-of-the-preliminary-data">4.2.2 Attributes of the preliminary data&lt;/h4>
&lt;p>&lt;strong>Seasonal Consistency&lt;/strong>: The preliminary data, that was pre-processed and extracted, was plotted to visualize the basic results. The data pertains to a particular duration of time in a specific seasonal time of the year, more importantly that spans the first two weeks of November for all the four years. This has been done to maintain consistency of results across the platform and to create as much as a robust framework as possible that can have high fidelity.&lt;/p>
&lt;p>&lt;strong>Data-points as x-axis&lt;/strong>: Additionally, it should be kept in mind that the data has already been time-stamped rigorously. More precisely, the databases that are uploaded to the USGS website have data tabulated in them that are arranged in a chronological manner. As a result, having the x-axis refer to actual data-points means the same if we had the x-axis refer to time instead. These plotted results have been provided in the next section.&lt;/p>
&lt;p>&lt;strong>Visualization of trends&lt;/strong>: The preliminary plotting of the data helps us to visualize the overall trends of the variation of the four important water-quality parameters. This gives an approximate idea regarding what we should normally expect from the water-quality data, the approximate maximum and minimum range of values, and it further helps in detecting any kind of outlier situations that might arise either due to the presence of artifacts, or nuisance environmental variables.&lt;/p>
&lt;h4 id="423-unsupervised-learning-k-means-clustering-analysis-safe--unsafe-centroid-calculation">4.2.3 Unsupervised learning: K-means clustering analysis (&amp;ldquo;Safe&amp;rdquo; &amp;amp; &amp;ldquo;Unsafe&amp;rdquo; Centroid calculation)&lt;/h4>
&lt;p>&lt;strong>General Clustering Analysis&lt;/strong>: The concept behind any clustering based approach involves an unsupervised learning mechanism. This means that the dataset traditionally does not come labelled and the task in hand is to find patterns within the data-set based on suitable metrics. These patterns help delineate the different clusters and classify the data by assigning them to one of these clusters. This process is usually carried out by measuring the euclidean distance of each point from the &amp;ldquo;centroids&amp;rdquo; of every cluster. The resultant clusters are created in such a way that the distance within the points in a particular cluster are minimized as much as possible whereas, the corresponding distance between points from different clusters are maximized. Figure 3 summarizes this concept of clustering technique.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/clusteranalysis.png" alt="clustering concept">&lt;/p>
&lt;p>&lt;strong>Figure 3:&lt;/strong> Concept of Clustering analysis adopted as an unsupervised learning process &lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>&lt;/p>
&lt;p>&lt;strong>K-means Classification: Centroid Calculation&lt;/strong>: The algorithm for this step first starts with selecting a random centroid value to start with to begin the iteration process. In order to be rigorous in this regard, the initial points for centroid values were chosen to be one standard deviation away from the median values for the four water-quality parameters. More importantly, two initial centroid values were chosen that would result in two clusters, one belonging to the safe water-standard cluster and the other belonging to the unsafe category. For the safe centroid value, the point chosen was such that it was one standard deviation lower than the median values for the temperature and specific conductance parameters, whereas it was one standard deviation higher than the median values for the pH and disolved oxygen level parameters. This logic was reversed in case of the unsafe centroid starting value. The intuition behind this approach comes from the fact that a lower temperature and specific conductance value means lower degree of exothermic reactions and lower amount dissolved salts which are typically the traits of unpolluted water sources, and which also have higher pH value (that is, less acidic) and higher level of dissolved oxygen. Hence, the initial centroid value for the &amp;ldquo;safe&amp;rdquo; category was chosen in this way. For the unsafe cateory, the metrics were simply reversed.&lt;/p>
&lt;p>&lt;strong>Iteration process&lt;/strong>: The next steps for the centroid calculation involves creating an iteration process which will keep updating and perfecting the centroid values upon every execution of the iteration. In this case, the condition for ending the iteration involved either exceeding fifty iterations or reaching the ideal situation where the new centroid value equals the previous centroid value. In the later case, it can be mentioned that the centroid calculation has converged to a specific ideal value. Fortunately, in the case of this project, it was possible to arrive at this convergence of centroid values with not too many iteration steps. The details of this process has been explained in the coding framework with appropriate comments.&lt;/p>
&lt;p>&lt;strong>Assigning of Clusters&lt;/strong>: At the end of the iteration step, we end up with the final centroid values for the safe and unsafe category. With the help of these values, we calculate the euclidean distance for every points and assign them to appropriate clusters to which they are closest to. In this way, we complete the unsupervised algorithm of clustering process for any unlabelled data that is provided to us. In this particular endeavor, we assign the value &amp;ldquo;0&amp;rdquo; for a predicted cluster indicating a safe set of water-quality values for a given point, and a value of &amp;ldquo;1&amp;rdquo; for an unsafe set of water-quality values for a given point. Figure 4 summarizes this idea behind the K-means clustering method that chiefly works as an unsupervised learning algorithm.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/kmeansclustering.png" alt="k-means idea">&lt;/p>
&lt;p>&lt;strong>Figure 4:&lt;/strong> Concept of Clustering analysis adopted as an unsupervised learning process &lt;sup id="fnref:11">&lt;a href="#fn:11" class="footnote-ref" role="doc-noteref">11&lt;/a>&lt;/sup>&lt;/p>
&lt;h4 id="424-display-of-results--analysis-of-any-given-sample-values-set">4.2.4 Display of results &amp;amp; analysis of any given sample values set&lt;/h4>
&lt;p>In the final step, we display all the results and relevant plots for this big-data analysis task. Additionally, based on the labelled data and predicted classes for safe and unsafe water-quality standards, it will now be possible to find whether an arbitrary set of data values, that represent water-quality data for a particular region, would be classified as safe or unsafe as per this technique. This has also been shown in the results section.&lt;/p>
&lt;h2 id="5-inference">5. Inference&lt;/h2>
&lt;h3 id="51-analysis-of-extracted-data-and-statistical-information">5.1 Analysis of extracted data and statistical information&lt;/h3>
&lt;p>The first preliminary set of results were analyzed to get a general idea of how the water quality paramters vary for the system in question. For the purposes of data visualization, the processed data (viewed as a data-frame in python) was first analyzed to understand the four primary water-quality parameters that are being worked upon. The data-frames for the big data sets are shown below, along with the corresponding statistical information that were evalauted for such attributes. Figure 5 shows the preliminary results that were obtained for the data visualization and statistical processing tasks.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/prelimresults.png" alt="Preliminary results">&lt;/p>
&lt;p>&lt;strong>Figure 5:&lt;/strong> Displaying results of data visualization and statistical information for the water-quality parameters&lt;/p>
&lt;p>In the above set of results, it should be worthwhile to note that temperature is measured in the celsius scale, specific conductance is measured in microsiemens per centimeter at 25 degree celsius, pH is measured in the usual standard range (between 0-14), and the level of dissolved oxygen is measured in milligrams per liter.&lt;/p>
&lt;p>Next, the content of the dataset, after it is processed in the software architecture, is plotted. It displays the alteration of the values (expressed in scatter plots) of the four main water-quality parameters (viz. Temperature, Specific Conductance, pH, and Dissolved Oxygen) over the period of time that starts from November 1 to November 14 for the four years involving 2017, 2018, 2019, and 2020.&lt;/p>
&lt;p>Figure 6 displays the scatter plot data for the &amp;ldquo;temperature&amp;rdquo; attribute in the year 2017.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/seventeentemp.png" alt="Temperature 2017">&lt;/p>
&lt;p>&lt;strong>Figure 6:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Temperature&amp;rdquo; (2017)&lt;/p>
&lt;p>Figure 7 displays the scatter plot data for the &amp;ldquo;specific conductance&amp;rdquo; attribute in the year 2017.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/seventeencond.png" alt="Conductance 2017">&lt;/p>
&lt;p>&lt;strong>Figure 7:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Specific Conductance&amp;rdquo; (2017)&lt;/p>
&lt;p>Figure 8 displays the scatter plot data for the &amp;ldquo;pH&amp;rdquo; attribute in the year 2017.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/seventeenph.png" alt="pH 2017">&lt;/p>
&lt;p>&lt;strong>Figure 8:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;pH&amp;rdquo; (2017)&lt;/p>
&lt;p>Figure 9 displays the scatter plot data for the &amp;ldquo;dissolved oxygen&amp;rdquo; attribute in the year 2017.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/seventeendox.png" alt="Dissolved Oxygen 2017">&lt;/p>
&lt;p>&lt;strong>Figure 9:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Dissolved Oxygen&amp;rdquo; (2017)&lt;/p>
&lt;p>Figure 10 displays the scatter plot data for the &amp;ldquo;temperature&amp;rdquo; attribute in the year 2018.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/eighteentemp.png" alt="Temperature 2018">&lt;/p>
&lt;p>&lt;strong>Figure 10:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Temperature&amp;rdquo; (2018)&lt;/p>
&lt;p>Figure 11 displays the scatter plot data for the &amp;ldquo;specific conductance&amp;rdquo; attribute in the year 2018.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/eighteencond.png" alt="Conductance 2018">&lt;/p>
&lt;p>&lt;strong>Figure 11:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Specific Conductance&amp;rdquo; (2018)&lt;/p>
&lt;p>Figure 12 displays the scatter plot data for the &amp;ldquo;pH&amp;rdquo; attribute in the year 2018.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/eighteenph.png" alt="pH 2018">&lt;/p>
&lt;p>&lt;strong>Figure 12:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;pH&amp;rdquo; (2018)&lt;/p>
&lt;p>Figure 13 displays the scatter plot data for the &amp;ldquo;dissolved oxygen&amp;rdquo; attribute in the year 2018.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/eighteendox.png" alt="Dissolved Oxygen 2018">&lt;/p>
&lt;p>&lt;strong>Figure 13:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Dissolved Oxygen&amp;rdquo; (2018)&lt;/p>
&lt;p>Figure 14 displays the scatter plot data for the &amp;ldquo;temperature&amp;rdquo; attribute in the year 2019.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/nineteentemp.png" alt="Temperature 2019">&lt;/p>
&lt;p>&lt;strong>Figure 14:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Temperature&amp;rdquo; (2019)&lt;/p>
&lt;p>Figure 15 displays the scatter plot data for the &amp;ldquo;specific conductance&amp;rdquo; attribute in the year 2019.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/nineteencond.png" alt="Conductance 2019">&lt;/p>
&lt;p>&lt;strong>Figure 15:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Specific Conductance&amp;rdquo; (2019)&lt;/p>
&lt;p>Figure 16 displays the scatter plot data for the &amp;ldquo;pH&amp;rdquo; attribute in the year 2019.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/nineteenph.png" alt="pH 2019">&lt;/p>
&lt;p>&lt;strong>Figure 16:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;pH&amp;rdquo; (2019)&lt;/p>
&lt;p>Figure 17 displays the scatter plot data for the &amp;ldquo;dissolved oxygen&amp;rdquo; attribute in the year 2019.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/nineteendox.png" alt="Dissolved Oxygen 2019">&lt;/p>
&lt;p>&lt;strong>Figure 17:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Dissolved Oxygen&amp;rdquo; (2019)&lt;/p>
&lt;p>Figure 18 displays the scatter plot data for the &amp;ldquo;temperature&amp;rdquo; attribute in the year 2020.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/twentytemp.png" alt="Temperature 2020">&lt;/p>
&lt;p>&lt;strong>Figure 18:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Temperature&amp;rdquo; (2020)&lt;/p>
&lt;p>Figure 19 displays the scatter plot data for the &amp;ldquo;specific conductance&amp;rdquo; attribute in the year 2020.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/twentycond.png" alt="Conductance 2020">&lt;/p>
&lt;p>&lt;strong>Figure 19:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Specific Conductance&amp;rdquo; (2020)&lt;/p>
&lt;p>Figure 20 displays the scatter plot data for the &amp;ldquo;pH&amp;rdquo; attribute in the year 2020.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/twentyph.png" alt="pH 2020">&lt;/p>
&lt;p>&lt;strong>Figure 20:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;pH&amp;rdquo; (2020)&lt;/p>
&lt;p>Figure 21 displays the scatter plot data for the &amp;ldquo;dissolved oxygen&amp;rdquo; attribute in the year 2020.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/twentydox.png" alt="Dissolved Oxygen 2020">&lt;/p>
&lt;p>&lt;strong>Figure 21:&lt;/strong> Scatter plot for the water-quality parameter involving &amp;ldquo;Dissolved Oxygen&amp;rdquo; (2020)&lt;/p>
&lt;h3 id="52-centroids--predicted-classesclusters">5.2 Centroids &amp;amp; Predicted Classes/Clusters&lt;/h3>
&lt;p>Figure 22 shows the final centroid values for the safe and unsafe water-quality standards for the year 2017. Furthermore, Figure 23 shows the predicted classes for the safe and unsafe clusters, which were calculated based on the results of the centroid values, for the same year of 2017.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/centroidsseventeen.png" alt="centroids for 2017">&lt;/p>
&lt;p>&lt;strong>Figure 22:&lt;/strong> Safe and unsafe centroid values for the year 2017.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/classpredictions.png" alt="clusters for 2017">&lt;/p>
&lt;p>&lt;strong>Figure 23:&lt;/strong> Predicted classes for safe (&amp;ldquo;0&amp;rdquo;) and unsafe (&amp;ldquo;1&amp;rdquo;) clusters for the year 2017.&lt;/p>
&lt;h3 id="53-heatmaps-for-the-years---2017-2018-2019-and-2020">5.3 Heatmaps for the years - 2017, 2018, 2019, and 2020&lt;/h3>
&lt;p>For the all the four years, heatmaps were plotted to get more information about the trend of the data. Chiefly, the heatmaps give us an empirical form of ideology relating to the degree of correlation between the different water-quality parameters in this data analysis task.&lt;/p>
&lt;p>Figure 24 visualizes the heat-map and shows the relationships between the various aquatic parameters for the year of 2017.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/heatmapseventeen.png" alt="hmap2017">&lt;/p>
&lt;p>&lt;strong>Figure 24:&lt;/strong> Heatmap for the water-quality parameters (Year - 2017)&lt;/p>
&lt;p>Figure 25 visualizes the heat-map and shows the relationships between the various aquatic parameters for the year of 2018.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/heatmapeighteen.png" alt="hmap2018">&lt;/p>
&lt;p>&lt;strong>Figure 25:&lt;/strong> Heatmap for the water-quality parameters (Year - 2018)&lt;/p>
&lt;p>Figure 26 visualizes the heat-map and shows the relationships between the various aquatic parameters for the year of 2019.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/heatmapnineteen.png" alt="hmap2019">&lt;/p>
&lt;p>&lt;strong>Figure 26:&lt;/strong> Heatmap for the water-quality parameters (Year - 2019)&lt;/p>
&lt;p>Figure 27 visualizes the heat-map and shows the relationships between the various aquatic parameters for the year of 2020.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/heatmaptwenty.png" alt="hmap2020">&lt;/p>
&lt;p>&lt;strong>Figure 27:&lt;/strong> Heatmap for the water-quality parameters (Year - 2020)&lt;/p>
&lt;h3 id="54-analysis-of-sample-set-of-values">5.4 Analysis of sample set of values&lt;/h3>
&lt;p>In this portion, we test the unsupervised learning mechanism on actual sample sets of water-quality values. For this purpose, we feed the sample values to the coding framework and based on the centroids calculated for the past four years, it is able to identify whether the given water sample belong in the safe or unsafe category. Further, if it belongs in the unsafe category, the system can further inform us the degree of criticality of the water-quality degradation. This is carried out by evaluating how many water quality parametric values are beyond the normal range. Based on this analysis, a critical nature is then displayed as an output result. As an example, a critical category of &amp;ldquo;2&amp;rdquo; would signify two of the water-quality parameters were beyond the normal range of values, while the others were normal. Needless to say, higher is the critical category level, the more degraded the water source is.&lt;/p>
&lt;p>Figure 28 displays the results obtained for specific sample values of water quality parameters.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/sampleresults.png" alt="sample values test">&lt;/p>
&lt;p>&lt;strong>Figure 28:&lt;/strong> Analysis of water sample values by ascertaining the degree of degradation based on critical level&lt;/p>
&lt;h3 id="55-benchmark-information">5.5 Benchmark information&lt;/h3>
&lt;p>Finally, the benchmark analysis results are shown below for the respective tasks carried out by the coding platform. Some important facts that should be kept in mind in this regard are as follows:&lt;/p>
&lt;ul>
&lt;li>The benchmark analysis was carried out using the cloudmesh benchmark procedure in Python (executed in Google Colab).&lt;/li>
&lt;li>A sleep-time of &amp;ldquo;5&amp;rdquo; was selected as the standard for the benchmark analysis and it has been adopted consistently for all the other benchmark calculations.&lt;/li>
&lt;li>The time values for the different benchmark results were not rounded off in this case as it was both important and interesting to know the minute differences between the different kinds of tasks that were carried out in this regard. It should be noted that the final benchmark value is exceptionally high since this step involves the part where the human user inputs the sample values for ascertaining the safety standard for a water source.&lt;/li>
&lt;/ul>
&lt;p>Figure 29 shows the benchmark results that were obtained for specific sections in the coding framework.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-312/raw/main/project/images/bmresults.png" alt="benchmark results">&lt;/p>
&lt;p>&lt;strong>Figure 29:&lt;/strong> Benchmark results for all the tasks that were carried out for this big data analysis task using Google Colab&lt;/p>
&lt;h2 id="6-conclusion">6. Conclusion&lt;/h2>
&lt;p>This research endeavor implements a big data analysis framework for analyzing toxicity of aquatic systems. It is an attempt where hardware and software meet together to give reliable results, and on the basis of which we are able to design an elaborate mechanism that can analyze other sample water sources and provide decisions regarding its degradation. Although the endeavor carried out in this example might not involve a plethora of high-end applications or intricate logic frameworks, it still provides a very decent foundational approach for carrying out toxicological analysis for water sources. Most importantly, it should be noted that the results obtained for sample values correspond to what we would normally expect for polluted and non-polluted sources of water. For instance, it was found that water sources with high values of specific conductance were categorized in the &amp;ldquo;unsafe&amp;rdquo; category which is to be expected since a high conductance value typically signifies the presence of dissolved salts and ions in the water source, which normally indicates that effluents or agricultural run-off might have made its way to the water source. Additionally, it was also found out that water samples with high values of dissolved oxygen levels were categorized in the &amp;ldquo;safe&amp;rdquo; category which is certainly true based on biological postulates.&lt;/p>
&lt;p>Of course, a more diverse array of data coupled with more scientific and enhanced ASV systems would have probably provided us with even better results. But as indicated earlier, this research endeavor provides a pragmatic foundational approach to conducting this kind of big data analytical work. We can build up on the logic presented in this endeavor to come up with even more advanced and robust version of toxicological analysis tasks.&lt;/p>
&lt;h2 id="7-acknowledgements">7. Acknowledgements&lt;/h2>
&lt;p>The author would like to thank Dr. Geoffrey Fox, Dr. Gregor von Laszewski, and the associate instructors in the &lt;em>FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em> course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article.&lt;/p>
&lt;h2 id="8-references">8. References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Valada A., Velagapudi P., Kannan B., Tomaszewski C., Kantor G., Scerri P. (2014) Development of a Low Cost Multi-Robot Autonomous Marine Surface Platform. In: Yoshida K., Tadokoro S. (eds) Field and Service Robotics. Springer Tracts in Advanced Robotics, vol 92. Springer, Berlin, Heidelberg. &lt;a href="https://doi.org/10.1007/978-3-642-40686-7_43">https://doi.org/10.1007/978-3-642-40686-7_43&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>M. Ludvigsen, J. Berge, M. Geoffroy, J. H. Cohen, P. R. De La Torre, S. M. Nornes, H. Singh, A. J. Sørensen, M. Daase, G. Johnsen, Use of an Autonomous Surface Vehicle reveals small-scale diel vertical migrations of zooplankton and susceptibility to light pollution under low solar irradiance. Sci. Adv. 4, eaap9887 (2018). &lt;a href="https://advances.sciencemag.org/content/4/1/eaap9887/tab-pdf">https://advances.sciencemag.org/content/4/1/eaap9887/tab-pdf&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Verfuss U., et al., (2019, March). A review of unmanned vehicles for the detection and monitoring of marine fauna. Marine Pollution Bulletin, Volume 140, Pages 17-29. Retrieved from &lt;a href="https://doi.org/10.1016/j.marpolbul.2019.01.009">https://doi.org/10.1016/j.marpolbul.2019.01.009&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>USGS Water Quality Data, Accessed: Nov. 2020, &lt;a href="https://waterdata.usgs.gov/nwis/qw">https://waterdata.usgs.gov/nwis/qw&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>EPA Water Quality Data, Accessed Nov. 2020, &lt;a href="https://www.epa.gov/waterdata/water-quality-data-download">https://www.epa.gov/waterdata/water-quality-data-download&lt;/a> &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>Read, E. K., Carr, L., De Cicco, L., Dugan, H. A., Hanson, P. C., Hart, J. A., Kreft, J., Read, J. S., and Winslow, L. A. (2017), Water quality data for national‐scale aquatic research: The Water Quality Portal, Water Resour. Res., 53, 1735– 1745, doi:10.1002/2016WR019993. &lt;a href="https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1002/2016WR019993">https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1002/2016WR019993&lt;/a> &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>Atlas Scientific team. Atlas Scientific Environmental Robotics. Retrieved from &lt;a href="https://atlas-scientific.com/">https://atlas-scientific.com/&lt;/a> &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>Sinha, Saptarshi. (2020) A Big-data analysis framework for Toxicological Study. Retrieved from &lt;a href="https://github.com/cybertraining-dsc/fa20-523-312/blob/main/project/code/toxicologyASV.ipynb">https://github.com/cybertraining-dsc/fa20-523-312/blob/main/project/code/toxicologyASV.ipynb&lt;/a> &lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>Google Colaboratory team. Google Colaboratory. Retrieved from &lt;a href="https://colab.research.google.com/">https://colab.research.google.com/&lt;/a> &lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>Tan, Steinback, Kumar (2004, April). Introduction to Data Mining, Lecture Notes for Chapter 8, Page 2. Accessed: Nov. 2020, &lt;a href="https://www-users.cs.umn.edu/~kumar001/dmbook/dmslides/chap8_basic_cluster_analysis.pdf">https://www-users.cs.umn.edu/~kumar001/dmbook/dmslides/chap8_basic_cluster_analysis.pdf&lt;/a> &lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:11" role="doc-endnote">
&lt;p>Alan J. (2019, November). K-means: A Complete Introduction. Retrieved from &lt;a href="https://towardsdatascience.com/k-means-a-complete-introduction-1702af9cd8c">https://towardsdatascience.com/k-means-a-complete-introduction-1702af9cd8c&lt;/a> &lt;a href="#fnref:11" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Report: Analysis of Future of Buffalo Breeds and Milk Production Growth in India</title><link>/report/fa20-523-326/project/project/</link><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate><guid>/report/fa20-523-326/project/project/</guid><description>
&lt;h1 id="heading">&lt;/h1>
&lt;p>&lt;a href="https://github.com/cybertraining-dsc/fa20-523-326/actions">&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/workflows/Check%20Report/badge.svg" alt="Check Report">&lt;/a>
&lt;a href="https://github.com/cybertraining-dsc/fa20-523-326/actions">&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/workflows/Status/badge.svg" alt="Status">&lt;/a>
Status: final, Type: Project&lt;/p>
&lt;p>Gangaprasad Shahapurkar, fa20-523-326, &lt;a href="https://github.com/cybertraining-dsc/fa20-523-326/blob/main/project/project.md">Edit&lt;/a> &lt;a href="https://github.com/cybertraining-dsc/fa20-523-326/blob/main/project/code/project.ipynb">Python Notebook&lt;/a>&lt;/p>
&lt;div class="pageinfo pageinfo-primary">
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>Water buffalo (&lt;strong>Bubalus bubalis&lt;/strong>) is also called &lt;em>Domestic Water Buffalo&lt;/em> or &lt;em>Asian Water Buffalo&lt;/em>. It is large bovid originating in Indian subcontinent, Southeast Asia, and China and today found in other regions of world - Europe, Australia, North America, South America and some African countries. There are two extant types recognized based on morphological and behavioral criteria:&lt;/p>
&lt;ol>
&lt;li>River Buffalo - Mostly found in Indian subcontinent and further west to the Balkans, Egypt, and Italy&lt;/li>
&lt;li>Swamp Buffalo - Found from west of Assam through Southeast Asia to the Yangtze valley of China in the east&lt;/li>
&lt;/ol>
&lt;p>India is the largest milk producer and consumer compared to other countries in the world and stands unique in terms of the largest share of milk being produced coming from buffaloes. The aim of this academic project is to study the livestock census data of buffalo breeds in India and their milk production using Empirical Benchmarking analysis method at state level. Looking at the small sample of data, our analysis indicates that we have been seeing increasing trends in past few years in livestock and milk production but there are considerable opportunities to increase production using combined interventions.&lt;/p>
&lt;p>Contents&lt;/p>
&lt;div class="toc">
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#1-introduction">1. Introduction&lt;/a>&lt;/li>
&lt;li>&lt;a href="#2-background-research-and-previous-work">2. Background Research and Previous Work&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-choice-of-datasets">3. Choice of Datasets&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-methodology">4. Methodology&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#41-software-components">4.1 Software Components&lt;/a>&lt;/li>
&lt;li>&lt;a href="#42-data-processing">4.2 Data Processing&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#421-eda">4.2.1 EDA&lt;/a>&lt;/li>
&lt;li>&lt;a href="#422-feature-engineering">4.2.2 Feature Engineering&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#43-modelling">4.3 Modelling&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#431-data-preperation">4.3.1 Data Preperation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#432-empirical-benchmarking-model">4.3.2 Empirical Benchmarking Model&lt;/a>&lt;/li>
&lt;li>&lt;a href="#433-linear-regression">4.3.3 Linear Regression&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#5-results">5. Results&lt;/a>&lt;/li>
&lt;li>&lt;a href="#6-conclusion">6. Conclusion&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-acknowledgements">7. Acknowledgements&lt;/a>&lt;/li>
&lt;li>&lt;a href="#8-references">8. References&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Keywords:&lt;/strong> hid 326, i532, buffalo, milk production, livestock, benchmarking, in-milk yield, agriculture, india, analysis&lt;/p>
&lt;h2 id="1-introduction">1. Introduction&lt;/h2>
&lt;p>Indian agriculture sector has been playing a vital role in overall contribution to Indian economy. Most of the rural community in the nation still make their livelihood on dairy farming or agriculture farming. Dairy farming itself has been on its progressive stage from past few years and it is contributing to almost more than 25% of agriculture Gross Domestic Product (GDP) &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. Livestock rearing has been integral part of the nation&amp;rsquo;s rural community and this sector is leveraging the economy in a big way considering the growth seen. It not only provides food, income, employment but also plays major role in life of farmers. It also does other contributions to the overall rural development of the nation. The output of livestock rearing such as milk, egg, meat, and wool provides everyday income to the farmers on daily basis, it provides nutrition to consumers and indirectly it helps in contributing to the overall economy and socio-economic development of the country.&lt;/p>
&lt;p>The world buffalo population is estimated at 185.29 million, spread in some 42 countries, of which 179.75 million (97%) are in Asia (Source: Fao.org/stat 2008). Hence major share of buffalo milk production in world comes from Asia (see Figure 1). India has 105.1 million and they comprise approximately 56.7 percent of the total world buffalo population. During the last 10 years, the world buffalo population increased by approximately 1.49% annually, by 1.53% in India, 1.45% in Asia and 2.67% in the rest of the world. Figure 1 shows worldwide share of milk production from buffalo breed. Figure 2 highlights percentage contribution of Asia including other top 2 contributors to world milk production.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/milk_production_world.png" alt="Milk Production World">&lt;/p>
&lt;p>&lt;strong>Figure 1:&lt;/strong> Production of Milk, whole fresh buffalo in World + (Total), Average 2013 - 2018 &lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/milk_production_by_region.png" alt="Milk Production Share">&lt;/p>
&lt;p>&lt;strong>Figure 2:&lt;/strong> Production share of Milk, whole fresh buffalo by region, Average 2013 - 2018 &lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="2-background-research-and-previous-work">2. Background Research and Previous Work&lt;/h2>
&lt;p>Production of milk and meat from buffaloes in Asian countries over the last decades has shown a varying pattern: in countries such as India, Sri Lanka, Pakistan and China. Buffaloes are known to be better at converting poor-quality roughage into milk and meat. They are reported to have 5% higher digestibility of crude fibre than high-yielding cows; and a 4% to 5% higher efficiency of utilization of metabolic energy for milk production &lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, &lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>After studying literatures and researches it was noticed that there has been some research around to quantify livestock yield gaps. There is no standard methodology, but multiple methods were combined for research. Researchers were able to calculate relative yield gaps for the dairy production in India and Ethiopia &lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. There was analysis based on attainable yields using Empirical Benchmarking, and Stochastic Frontier Analysis to evaluate possible interventions for increasing production (household modelling). It was noticed that large yield gaps exist for dairy production in both countries, and packages of interventions are required to bridge these gaps rather than single interventions. Part of the research was borrowed to analyze the limited dataset chosen as part of this project.&lt;/p>
&lt;h2 id="3-choice-of-datasets">3. Choice of Datasets&lt;/h2>
&lt;p>Number of online literatures and datasets were checked to find out suitable dataset required for this project analysis. Below dataset were found promising:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://dahd.nic.in/about-us/divisions/statistics">DAHD Data&lt;/a> &lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>, &lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>, &lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup>, &lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup> (&lt;strong>20th India Livestock Census Data&lt;/strong>)&lt;/li>
&lt;/ol>
&lt;p>The Animal Husbandry Statistics Division of the Department of Animal Husbandry &amp;amp; Dairying Division (DAHD) is responsible for the generation of animal husbandry statistics through the schemes of livestock census and integrated sample surveys &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. Survey is defined by Indian Agriculture Statistics Research Institute (IASRI) &lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>. This is the only scheme through which considerable data, particularly on the production estimate of major livestock products, is being generated for policy formulation in the livestock sector. It is mandate for this division to&lt;/p>
&lt;ul>
&lt;li>Conduct quinquennial livestock census&lt;/li>
&lt;li>Conduct annual sample survey through integrated sample survey&lt;/li>
&lt;li>Publish annual production estimates of milk, eggs, meat, wool and other related animal husbandry statistics based on survey&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>&lt;a href="http://www.fao.org/faostat/en/#data">FAO Data&lt;/a> &lt;sup id="fnref:11">&lt;a href="#fn:11" class="footnote-ref" role="doc-noteref">11&lt;/a>&lt;/sup>, &lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/li>
&lt;/ol>
&lt;p>Food and Agriculture Organization (FAO) of United Nation publishes worldwide data on the aspects of dairy farming which can also be visualized online with the options provided. Some of the data from this source was used to extract useful summary needed in analysis.&lt;/p>
&lt;ol start="3">
&lt;li>[UIDAI Data] (&lt;a href="https://uidai.gov.in">https://uidai.gov.in&lt;/a>) &lt;sup id="fnref:12">&lt;a href="#fn:12" class="footnote-ref" role="doc-noteref">12&lt;/a>&lt;/sup>&lt;/li>
&lt;/ol>
&lt;p>Unique Identification Authority of India (UIDAI) was created with the objective to issue Unique Identification numbers (UID), named as &lt;strong>Aadhaar&lt;/strong>, to all residents of India. Projected population data of 2020 was extracted from this source.&lt;/p>
&lt;p>In addition to above, other demographics information such as area of each state, district count was extracted from OpenStreetMap &lt;sup id="fnref:13">&lt;a href="#fn:13" class="footnote-ref" role="doc-noteref">13&lt;/a>&lt;/sup>. Agricultural zone information was extracted from report of Food and Nutrition Security Analysis, India, 2019 &lt;sup id="fnref:14">&lt;a href="#fn:14" class="footnote-ref" role="doc-noteref">14&lt;/a>&lt;/sup>.&lt;/p>
&lt;h2 id="4-methodology">4. Methodology&lt;/h2>
&lt;h3 id="41-software-components">4.1 Software Components&lt;/h3>
&lt;p>This project has been implemented in Python 3.7 version. Jupyter Notebook application was used to develop the code and produce a notebook document. Jupyter notebook is a Client-Server architecture-based application which allows modification and execution of code through web browser. Jupyter notebook can be installed locally and accessed through localhost browser or it can be installed on a remote machine and accessed via internet &lt;sup id="fnref:15">&lt;a href="#fn:15" class="footnote-ref" role="doc-noteref">15&lt;/a>&lt;/sup>, &lt;sup id="fnref:16">&lt;a href="#fn:16" class="footnote-ref" role="doc-noteref">16&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Following python libraries were used in overall code development. Before running the code, one must make sure that these libraries are installed.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Pandas&lt;/strong> This is a high performance and easy to use library. It was used for data cleaning, data analysis, &amp;amp; data preparation.&lt;/li>
&lt;li>&lt;strong>NumPy&lt;/strong> NumPy is python core library used for scientific computing. Some of the basic functions were used in this project.&lt;/li>
&lt;li>&lt;strong>Matplotlib&lt;/strong> This is a comprehensive library used for static, animated and interactive visualization.&lt;/li>
&lt;li>&lt;strong>OS&lt;/strong> This is another standard library of Python which provides miscellaneous operating system interface functions.&lt;/li>
&lt;li>&lt;strong>Scikit-learn (Sklearn)&lt;/strong> Robust library that provides efficient tools for machine learning and statistical modelling.&lt;/li>
&lt;li>&lt;strong>Seaborn&lt;/strong> Python data visualization library based on matplotlib.&lt;/li>
&lt;/ul>
&lt;h3 id="42-data-processing">4.2 Data Processing&lt;/h3>
&lt;p>The raw data retrieved from various sources was in excel or report format. The data was pre-processed and stored back in csv format for the purpose of this project and to easily process it. This dataset was further processed through various stages via EDA, feature engineering and modelling.&lt;/p>
&lt;h4 id="421-eda">4.2.1 EDA&lt;/h4>
&lt;p>Preprocessed dataset selected for this analysis contained information at the state level. There were two seperate pre-processed dataset used. Below was the nature of the attributes in the main dataset which had buffalo information:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>State Name:&lt;/strong> Name of each state in India. One record for each state.&lt;/li>
&lt;li>&lt;strong>Buffalo count:&lt;/strong> Total number of male and female buffaloes. Data recorded for 14 types of buffalo breeds. One attribute for each type of female and male breeds.&lt;/li>
&lt;li>&lt;strong>In Milk animals:&lt;/strong> Number of In-Milk animals per state (figures in 000 no&amp;rsquo;s) recorded each year from 2013 to 2019. One attribute per year&lt;/li>
&lt;li>&lt;strong>Yield per In-Milk animal:&lt;/strong> Yield per In-Milk animals per state (figures in kg/day) recorded each year from 2013 to 2019. One attribute per year.&lt;/li>
&lt;li>&lt;strong>Milk production:&lt;/strong> - Milk production per state (figures in 000 tones) recorded each year from 2013 to 2019. One attribute per year.&lt;/li>
&lt;/ul>
&lt;p>Below was the nature of the attributes in the secondary dataset which had demographic information:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Geographic information:&lt;/strong> features captured at state level where each feature represented - projected population of 2020, total districts in each state, total villages in each state, official area of each state in square kilometer.&lt;/li>
&lt;li>&lt;strong>Climatic information:&lt;/strong> One of attribute for each zone highlighted in Table 1&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Table 1:&lt;/strong> Agro climatic regions in India&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Zones&lt;/th>
&lt;th>Agro-Climatic Regions&lt;/th>
&lt;th>States&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Zone 1&lt;/td>
&lt;td>Western Himalayan Region&lt;/td>
&lt;td>Jammu and Kashmir, Himachal Pradesh, Uttarakhand&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 2&lt;/td>
&lt;td>Eastern Himalayan Region&lt;/td>
&lt;td>Assam, Sikkim, West Bengal, Manipur, Mizoram, Andhra Pradesh, Meghalaya, Tripura&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 3&lt;/td>
&lt;td>Lower Gangetic Plains Region&lt;/td>
&lt;td>West Bengal&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 4&lt;/td>
&lt;td>Middle Gangetic Plains Region&lt;/td>
&lt;td>Uttar Pradesh, Bihar, Jharkhand&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 5&lt;/td>
&lt;td>Upper Gangetic Plains Region&lt;/td>
&lt;td>Uttar Pradesh&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 6&lt;/td>
&lt;td>Trans-Gangetic Plains Region&lt;/td>
&lt;td>Punjab, Haryana, Delhi and Rajasthan&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 7&lt;/td>
&lt;td>Eastern Plateau and Hills Region&lt;/td>
&lt;td>Maharashtra, Chhattisgarh, Jharkhand, Orissa and West Bengal&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 8&lt;/td>
&lt;td>Central Plateau and Hills Region&lt;/td>
&lt;td>Madhya Pradesh, Rajasthan, Uttar Pradesh, Chhattisgarh&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 9&lt;/td>
&lt;td>Western Plateau and Hills Region&lt;/td>
&lt;td>Maharashtra, Madhya Pradesh, Chhattisgarh and Rajasthan&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 10&lt;/td>
&lt;td>Southern Plateau and Hills Region&lt;/td>
&lt;td>Andhra Pradesh, Karnataka, Tamil Nadu, Telangana, Chhattisgarh&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 11&lt;/td>
&lt;td>East Coast Plains and Hills Region&lt;/td>
&lt;td>Orissa, Andhra Pradesh, Tamil Nadu and Pondicherry&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 12&lt;/td>
&lt;td>West Coast Plains and Ghat Region&lt;/td>
&lt;td>Tamil Nadu, Kerala, Goa, Karnataka, Maharashtra, Gujarat&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 13&lt;/td>
&lt;td>Gujarat Plains and Hills Region&lt;/td>
&lt;td>Gujarat, Madhya Pradesh, Rajasthan, Maharashtra&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 14&lt;/td>
&lt;td>Western Dry Region&lt;/td>
&lt;td>Rajasthan&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Zone 15&lt;/td>
&lt;td>The Islands Region&lt;/td>
&lt;td>Andaman and Nicobar, Lakshadweep&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Figure 3 shows top 10 states from livestock census having total number of buffalo counts. Uttar Pradesh was the state which reported a greater number of buffaloes compared to any other states in the country.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/top10states.png" alt="Milk Production Share">&lt;/p>
&lt;p>&lt;strong>Figure 3:&lt;/strong> Top 10 state by buffalo counts&lt;/p>
&lt;p>There were greater number of female buffaloes reported in country (80%) compared to male buffalo breeds.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/buffaloshare.png" alt="Milk Production Share">&lt;/p>
&lt;p>&lt;strong>Figure 4:&lt;/strong> Buffalo breeds ratio by male and female&lt;/p>
&lt;h4 id="422-feature-engineering">4.2.2 Feature Engineering&lt;/h4>
&lt;p>Murrah buffalo shown in Figure 5 is the most productive and globally famous breed &lt;sup id="fnref:17">&lt;a href="#fn:17" class="footnote-ref" role="doc-noteref">17&lt;/a>&lt;/sup>, &lt;sup id="fnref:18">&lt;a href="#fn:18" class="footnote-ref" role="doc-noteref">18&lt;/a>&lt;/sup>. This breed is resistant to diseases and can adjust to various Indian climate conditions.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/murrah_buffalo.jpeg" alt="Murrah buffalo">&lt;/p>
&lt;p>&lt;strong>Figure 5:&lt;/strong> Murrah buffalo (Bubalus bubalis), globally famous local breed of Haryana, were exported to many nations &lt;sup id="fnref:19">&lt;a href="#fn:19" class="footnote-ref" role="doc-noteref">19&lt;/a>&lt;/sup>, &lt;sup id="fnref:20">&lt;a href="#fn:20" class="footnote-ref" role="doc-noteref">20&lt;/a>&lt;/sup>&lt;/p>
&lt;p>In feature engineering multiple attributes were derived needed for modelling or during analysis. Table 2 shows percentage share of Murrah buffalo breed in top 10 states having highest number of total buffaloes. Though Uttar Pradesh was top state in India in terms of total number of buffaloes but percentage share of Murrah buffalo was more in state of Punjab.&lt;/p>
&lt;p>&lt;strong>Table 2:&lt;/strong> Murrah buffalo percent share in top 10 state with buffalo count&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>State Name&lt;/th>
&lt;th>Murrah Buffalo Count&lt;/th>
&lt;th>Total Buffalo Count&lt;/th>
&lt;th>% Murrah Breed&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>UTTAR PRADESH&lt;/td>
&lt;td>20110852&lt;/td>
&lt;td>30625334&lt;/td>
&lt;td>65.67&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>RAJASTHAN&lt;/td>
&lt;td>6448563&lt;/td>
&lt;td>12976095&lt;/td>
&lt;td>49.70&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ANDHRA PRADESH&lt;/td>
&lt;td>5227270&lt;/td>
&lt;td>10622790&lt;/td>
&lt;td>49.21&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>HARYANA&lt;/td>
&lt;td>5011145&lt;/td>
&lt;td>6085312&lt;/td>
&lt;td>82.35&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>PUNJAB&lt;/td>
&lt;td>4116508&lt;/td>
&lt;td>5159734&lt;/td>
&lt;td>79.78&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BIHAR&lt;/td>
&lt;td>2419952&lt;/td>
&lt;td>7567233&lt;/td>
&lt;td>31.98&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MADHYA PRADESH&lt;/td>
&lt;td>1446078&lt;/td>
&lt;td>8187989&lt;/td>
&lt;td>17.66&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MAHARASHTRA&lt;/td>
&lt;td>986981&lt;/td>
&lt;td>5594392&lt;/td>
&lt;td>17.64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>TAMIL NADU&lt;/td>
&lt;td>435634&lt;/td>
&lt;td>780431&lt;/td>
&lt;td>55.82&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>UTTARAKHAND&lt;/td>
&lt;td>378917&lt;/td>
&lt;td>987775&lt;/td>
&lt;td>38.36&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Survey dataset had three primary attributes reported at the state level. Data reported from 2013 to 2019 for in-milk animals, yield per in-milk animals and milk production per state were averaged for analysis purpose. Total number of buffaloes per breed type were calculated from the data provided in the dataset. Following list of breeds were identified from dataset &lt;sup id="fnref:21">&lt;a href="#fn:21" class="footnote-ref" role="doc-noteref">21&lt;/a>&lt;/sup>.&lt;/p>
&lt;ul>
&lt;li>Banni&lt;/li>
&lt;li>Bhadawari&lt;/li>
&lt;li>Chilika&lt;/li>
&lt;li>Jaffarabadi&lt;/li>
&lt;li>Kalahandi&lt;/li>
&lt;li>Marathwadi&lt;/li>
&lt;li>Mehsana&lt;/li>
&lt;li>Murrah&lt;/li>
&lt;li>Nagpuri&lt;/li>
&lt;li>Nili Ravi&lt;/li>
&lt;li>Non-Descript&lt;/li>
&lt;li>Pandharpuri&lt;/li>
&lt;li>Surti&lt;/li>
&lt;li>Toda&lt;/li>
&lt;/ul>
&lt;p>Data showed that Uttar Pradesh had highest average milk production with in the top 10 states whereas Punjab state had highest average yield per in-milk animals. Figure 6 shows the share of top 3 breeds in both the state. Common attribute seen between two states was highest number of Murrah breed buffaloes compared to other breeds.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/punjab_up_state.png" alt="TOP TWO States">&lt;/p>
&lt;p>&lt;strong>Figure 6:&lt;/strong> Top 3 types of buffalo breeds of Uttar Pradesh and Punjab&lt;/p>
&lt;h3 id="43-modelling">4.3 Modelling&lt;/h3>
&lt;h4 id="431-data-preperation">4.3.1 Data Preperation&lt;/h4>
&lt;p>Data from main dataset and supplementary dataset which was demographics data was merged into one dataset. This dataset was not labelled and it was small dataset. We considered average milk production as our target label for analysis. The rest of the features were divided based on categorical and numerical nature. Our dataset did not had any categorical features except state name which was used as index column so no futher processing was considered for this attribute. All the features were of numerical nature and all the data points were not on same scale. Hence datapoints were normalized for further processing.&lt;/p>
&lt;h4 id="432-empirical-benchmarking-model">4.3.2 Empirical Benchmarking Model&lt;/h4>
&lt;p>There are two dominant approach of economic modelling to estimate the production behavior - Empirical Benchmarking and Stochastic Frontier Analysis &lt;sup id="fnref:22">&lt;a href="#fn:22" class="footnote-ref" role="doc-noteref">22&lt;/a>&lt;/sup>, &lt;sup id="fnref:23">&lt;a href="#fn:23" class="footnote-ref" role="doc-noteref">23&lt;/a>&lt;/sup>. Empirical Benchmarking is simple modelling method, and it is one of the two dominant approach. This method was used to analyze past 6 years of data points available in the livestock dataset. In this approach milk production data of past 6 years was averaged. Top 10 states with most milk production reported were compared with average of the whole sample. The problem analyzed as part of this project was relatively small. The comparison did not consider all possible characteristics for modelling.&lt;/p>
&lt;p>Correlation of target variable with various demographics features available in the dataset was calculated. Table 3 and Table 4 shows the positive and negative coorelation with target variable average milk production respectively. We noticed from Table 3 that average milk production contribution was getting affected by number of in-milk animals reported in the particular year census data and their was also factor of climatic conditions affecting the milk production. India is divided into 15 Agro climate zones. Agro zone 6 is Trans-Gangetic Plains region. Indian states Chandigarh, Delhi, Haryana, Punjab, Rajasthan (some parts) falls under this zone. Agricultural development has shown phenomenal growth in overall productivity and in providing better environment for dairy farming in this zone &lt;sup id="fnref:24">&lt;a href="#fn:24" class="footnote-ref" role="doc-noteref">24&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;strong>Table 3:&lt;/strong> Positive coorelation of target with demographics features&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Feature&lt;/th>
&lt;th>%&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>avg_milk_production&lt;/td>
&lt;td>1.00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>avg_in_milk&lt;/td>
&lt;td>0.95&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>total_female&lt;/td>
&lt;td>0.90&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>total_male&lt;/td>
&lt;td>0.71&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>agro_climatic_zone6&lt;/td>
&lt;td>0.50&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Table 4:&lt;/strong> Negative coorelation of target with demographics features&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Feature&lt;/th>
&lt;th>%&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>official_area_sqkm&lt;/td>
&lt;td>-0.17&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>agro_climatic_zone2&lt;/td>
&lt;td>-0.19&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>avg_yield_in_milk&lt;/td>
&lt;td>-0.23&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>district_count&lt;/td>
&lt;td>-0.34&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>proj_population_2020&lt;/td>
&lt;td>-0.94&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="433-linear-regression">4.3.3 Linear Regression&lt;/h4>
&lt;p>Our target variable considered was a continous variable. In an attempt to perform dimension reduction, Principal Component Analysis (PCA) was applied to available limited dataset. In the example presented, an pipeline was constructed that had dimension reduction followed by Linear regression classifier. Grid search cross validation was applied (GridSearchCV) to find the best parameters and score. Linear regression was applied with default parameter settings whereas parameter range was passed for PCA. Below is snapshot of pipeline implemented.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#8f5902;font-style:italic"># Define a pipeline to search for the best combination of PCA truncation&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># and classifier regularization.&lt;/span>
&lt;span style="color:#000">pca&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">PCA&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># Linear Regression without parameters&lt;/span>
&lt;span style="color:#000">linear&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">LinearRegression&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#000">full_pipeline_with_predictor&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">Pipeline&lt;/span>&lt;span style="color:#000;font-weight:bold">([&lt;/span>
&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;preparation&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">num_pipeline&lt;/span>&lt;span style="color:#000;font-weight:bold">),&lt;/span>
&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;pca&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>&lt;span style="color:#000">pca&lt;/span>&lt;span style="color:#000;font-weight:bold">),&lt;/span>
&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;linear&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">linear&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#000;font-weight:bold">])&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># Parameters of pipelines:&lt;/span>
&lt;span style="color:#000">param_grid&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#4e9a06">&amp;#39;pca__n_components&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">5&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">15&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">30&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">45&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">64&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="5-results">5. Results&lt;/h2>
&lt;p>Based on simple Empirical Benchmarking Analysis and trends noticed in data it appears that it is possible to increase production past currently attainable yields (see Figure 7). The current scale of the yield does indicate that, leading states have best breeds of buffaloes. Different methods of analyzing yield gaps can be combined to give estimates of attainable yields. It will also help to evaluate possible interventions to increase production and profits.&lt;/p>
&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/avgmilkproduction.png" alt="TOP 10 States">&lt;/p>
&lt;p>&lt;strong>Figure 7:&lt;/strong> Average milk production in top 10 state with benchmark&lt;/p>
&lt;p>The best parameter came out of the pipeline implemented are highlighted here. The results were not promising due the limited dataset so further experimentation was not attempted, but one thing was noticed that cross validated score came out to 0.28 and dimension reduction to 5 components.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#000">Best&lt;/span> &lt;span style="color:#000">parameter&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">CV&lt;/span> &lt;span style="color:#000">score&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0.282&lt;/span>&lt;span style="color:#000;font-weight:bold">):&lt;/span>
&lt;span style="color:#000;font-weight:bold">{&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;pca__n_components&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">5&lt;/span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">PCA&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">copy&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#3465a4">True&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">iterated_power&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;auto&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">n_components&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#3465a4">None&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">random_state&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#3465a4">None&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#000">svd_solver&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;auto&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">tol&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">0.0&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">whiten&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#3465a4">False&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://github.com/cybertraining-dsc/fa20-523-326/raw/main/project/images/covariance.png" alt="COV Analysis">&lt;/p>
&lt;p>&lt;strong>Figure 8:&lt;/strong> Covariance Heat Map&lt;/p>
&lt;p>We were able to calculate correlation of census data with other socioeconomic factors like population information, climate information (see Figure 8). The biggest probable limitation here was availability of good quality data. It would have been possible to conduct the analysis at finer level if more granular level data would have been available. Our analysis had to be done state level rather than at district level or specific area.&lt;/p>
&lt;h2 id="6-conclusion">6. Conclusion&lt;/h2>
&lt;p>The analysis done above with the limited dataset showed that there are considerable gaps in the average yield per in-milk buffalo of state Punjab and Uttar Pradesh, compared to other states in top 10 list. These states have larger share of Murrah breed buffaloes. Based on the data trends it appears that it is possible to increase the production past current attenable numbers. However, this would need to combine different methods and multiple strategies.&lt;/p>
&lt;h2 id="7-acknowledgements">7. Acknowledgements&lt;/h2>
&lt;p>The author would like to thank Dr. Gregor von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the &lt;em>FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em> course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article.&lt;/p>
&lt;h2 id="8-references">8. References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>PIB Delhi. (2019). Department of Animal Husbandry &amp;amp; Dairying releases 20th Livestock Census, 16 (Oct 2019).
&lt;a href="https://pib.gov.in/PressReleasePage.aspx?PRID=1588304">https://pib.gov.in/PressReleasePage.aspx?PRID=1588304&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>FAO - Food and Agriculture Organization of United Nation, Accessed: Nov. 2020, &lt;a href="http://www.fao.org/faostat/en/#data">http://www.fao.org/faostat/en/#data&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Mudgal, V.D. (1988). &amp;ldquo;Proc. of the Second World Buffalo Congress, New Delhi, India&amp;rdquo;, 12 to 17 Dec.:454. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Alessandro, Nardone. (2010). &amp;ldquo;Buffalo Production and Research&amp;rdquo;. Italian Journal of Animal Science. 5. 10.4081/ijas.2006.203. &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Mayberry, Dianne (07/2017). Yield gap analyses to estimate attainable bovine milk yields and evaluate options to increase production in Ethiopia and India. Agricultural systems (0308-521X), 155 , p. 43. &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>Department of Animal Husbandry and Dairying. &lt;a href="http://dahd.nic.in/about-us/divisions/statistics">http://dahd.nic.in/about-us/divisions/statistics&lt;/a> &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>Department of Animal Husbandry and Dairying, Accessed: Oct. 2020, &lt;a href="http://dadf.gov.in/sites/default/filess/20th%20Livestock%20census-2019%20All%20India%20Report.pdf">http://dadf.gov.in/sites/default/filess/20th%20Livestock%20census-2019%20All%20India%20Report.pdf&lt;/a> &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>Department of Animal Husbandry and Dairying, Accessed: Oct. 2020, &lt;a href="http://dadf.gov.in/sites/default/filess/Village%20and%20Ward%20Level%20Data%20%5BMale%20%26%20Female%5D.xlsx">http://dadf.gov.in/sites/default/filess/Village%20and%20Ward%20Level%20Data%20%5BMale%20%26%20Female%5D.xlsx&lt;/a> &lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>Department of Animal Husbandry and Dairying, Accessed: Oct. 2020, &lt;a href="http://dadf.gov.in/sites/default/filess/District-wise%20buffalo%20population%202019_0.pdf">http://dadf.gov.in/sites/default/filess/District-wise%20buffalo%20population%202019_0.pdf&lt;/a> &lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>IASRI - Indian Agriculture Statistics Research Institute. &lt;a href="https://iasri.icar.gov.in/">https://iasri.icar.gov.in/&lt;/a> &lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:11" role="doc-endnote">
&lt;p>F.A.O. (2008). Food and Agriculture Organization. Rome Italy. STAT &lt;a href="http://database.www.fao.org">http://database.www.fao.org&lt;/a> &lt;a href="#fnref:11" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:12" role="doc-endnote">
&lt;p>Unique Identification Authority of India, Accessed: Nov. 2020, &lt;a href="https://uidai.gov.in/images/state-wise-aadhaar-saturation.pdf">https://uidai.gov.in/images/state-wise-aadhaar-saturation.pdf&lt;/a> &lt;a href="#fnref:12" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:13" role="doc-endnote">
&lt;p>OpenStreetMap, Accessed: Nov. 2020, &lt;a href="https://wiki.openstreetmap.org/wiki/Main_Page">https://wiki.openstreetmap.org/wiki/Main_Page&lt;/a> &lt;a href="#fnref:13" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:14" role="doc-endnote">
&lt;p>Food and Nutrition Security Analysis, India, 2019, Accessed: Nov. 2020, &lt;a href="http://mospi.nic.in/sites/default/files/publication_reports/document%281%29.pdf">http://mospi.nic.in/sites/default/files/publication_reports/document%281%29.pdf&lt;/a> &lt;a href="#fnref:14" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:15" role="doc-endnote">
&lt;p>Corey Schafer. Jupyter Notebook Tutorial: Introduction, Setup, and Walkthrough. (Sep. 22, 2016). Accessed: Nov. 07, 2020. [Online Video]. Available: &lt;a href="https://www.youtube.com/watch?v=HW29067qVWk">https://www.youtube.com/watch?v=HW29067qVWk&lt;/a> &lt;a href="#fnref:15" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:16" role="doc-endnote">
&lt;p>&lt;em>The Jupyter Notebook&lt;/em>. Jupyter Team. Accessed: Nov. 07, 2020. [Online]. Available: &lt;a href="https://jupyter-notebook.readthedocs.io/en/stable/notebook.html">https://jupyter-notebook.readthedocs.io/en/stable/notebook.html&lt;/a> &lt;a href="#fnref:16" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:17" role="doc-endnote">
&lt;p>Bharathi Dairy Farm. &lt;a href="http://www.bharathidairyfarm.com/about-murrah.php">http://www.bharathidairyfarm.com/about-murrah.php&lt;/a> &lt;a href="#fnref:17" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:18" role="doc-endnote">
&lt;p>Water Buffalo. Accessed: Oct 26, 2020. [Online]. Available: &lt;a href="https://en.wikipedia.org/wiki/Water_buffalo">https://en.wikipedia.org/wiki/Water_buffalo&lt;/a> &lt;a href="#fnref:18" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:19" role="doc-endnote">
&lt;p>Kleomarlo. Own work, CC BY-SA 3.0. [Online]. Available: &lt;a href="https://commons.wikimedia.org/w/index.php?curid=4349862">https://commons.wikimedia.org/w/index.php?curid=4349862&lt;/a> &lt;a href="#fnref:19" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:20" role="doc-endnote">
&lt;p>ICAR - Central Institute for Research on Buffaloes. &lt;a href="https://cirb.res.in/">https://cirb.res.in/&lt;/a> &lt;a href="#fnref:20" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:21" role="doc-endnote">
&lt;p>List of Water Buffalo Breeds. Accessed: Oct 26, 2020. [Online]. Available: &lt;a href="https://en.wikipedia.org/wiki/List_of_water_buffalo_breeds">https://en.wikipedia.org/wiki/List_of_water_buffalo_breeds&lt;/a> &lt;a href="#fnref:21" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:22" role="doc-endnote">
&lt;p>Bogetoft P., Otto L. (2011) Stochastic Frontier Analysis SFA. In: Benchmarking with DEA, SFA, and R. International Series in Operations Research &amp;amp; Management Science, vol 157. Springer, New York, NY. &lt;a href="https://doi.org/10.1007/978-1-4419-7961-2_7">https://doi.org/10.1007/978-1-4419-7961-2_7&lt;/a> &lt;a href="#fnref:22" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:23" role="doc-endnote">
&lt;p>Aigner, Dennis (07/1977). &amp;ldquo;Formulation and estimation of stochastic frontier production function models&amp;rdquo;. Journal of econometrics (0304-4076), 6 (1), p. 21. &lt;a href="https://doi.org/10.1016/0304-4076(77)90052-5">https://doi.org/10.1016/0304-4076(77)90052-5&lt;/a> &lt;a href="#fnref:23" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:24" role="doc-endnote">
&lt;p>Farm Mechanization-Department of Agriculture and Cooperation, India, Accessed: Nov. 2020, &lt;a href="http://farmech.gov.in/06035-04-ACZ6-15052006.pdf">http://farmech.gov.in/06035-04-ACZ6-15052006.pdf&lt;/a> &lt;a href="#fnref:24" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Report: Estimating Soil Moisture Content Using Weather Data</title><link>/report/fa20-523-305/project/project/</link><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate><guid>/report/fa20-523-305/project/project/</guid><description>
&lt;p>&lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/actions">&lt;img src="https://github.com/cybertraining-dsc/fa20-523-305/workflows/Check%20Report/badge.svg" alt="Check Report">&lt;/a>
&lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/actions">&lt;img src="https://github.com/cybertraining-dsc/fa20-523-305/workflows/Status/badge.svg" alt="Status">&lt;/a>
Status: final, Type: Project&lt;/p>
&lt;p>Cody Harris, &lt;a href="mailto:harrcody@iu.edu">harrcody@iu.edu&lt;/a>, &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305">fa20-523-305&lt;/a>, &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/edit/main/project/project.md">Edit&lt;/a>&lt;/p>
&lt;p>Code: &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/blob/main/project/code/ml_pipeline.ipynb">ml_pipeline.ipynb&lt;/a>
Data: &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/tree/main/project/data">data&lt;/a>&lt;/p>
&lt;div class="pageinfo pageinfo-primary">
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>As the world is gripped with finding solutions
to problems such as food and water shortages, the study of agriculture could improve where we stand with both of these problems. By integrating weather and sensor data, a model could be created to estimate soil moisture based on weather data that is easily accessible. While some farmers could afford to have many moisture sensors and monitor them, many would not have the funds or resources to keep track of the soil moisture long term. A solution would be to allow farmers to contract out a limited study of their land using sensors and then this model would be able to predict soil moistures from weather data. This collection of data, and predictions could be used on their own or as a part of a larger agricultural solution.&lt;/p>
&lt;p>Contents&lt;/p>
&lt;div class="toc">
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#1-introduction">1. Introduction&lt;/a>&lt;/li>
&lt;li>&lt;a href="#2-background">2. Background&lt;/a>&lt;/li>
&lt;li>&lt;a href="#3-datasets">3. Datasets&lt;/a>&lt;/li>
&lt;li>&lt;a href="#4-data-cleaning-and-aggregation">4. Data Cleaning and Aggregation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#5-pipeline-for-preprocessing">5. Pipeline for Preprocessing&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#51-loading-and-joining-data">5.1 Loading and Joining Data&lt;/a>&lt;/li>
&lt;li>&lt;a href="#52-feature-engineering">5.2 Feature Engineering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#53-generic-pipeline">5.3 Generic Pipeline&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#6-multiple-models-for-multiple-soil-depths">6. Multiple Models for Multiple Soil Depths&lt;/a>&lt;/li>
&lt;li>&lt;a href="#7-splitting-data-into-train-and-test">7. Splitting Data into Train and Test&lt;/a>&lt;/li>
&lt;li>&lt;a href="#8-preliminary-analysis-and-eda">8. Preliminary Analysis and EDA&lt;/a>&lt;/li>
&lt;li>&lt;a href="#9-initial-model-testing-regressor">9. Initial Model Testing (Regressor)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#10-classifier-vs-regressor">10. Classifier vs. Regressor&lt;/a>&lt;/li>
&lt;li>&lt;a href="#11-various-other-linear-regression-model-experiments">11. Various Other Linear Regression Model Experiments&lt;/a>&lt;/li>
&lt;li>&lt;a href="#12-other-models">12. Other Models&lt;/a>&lt;/li>
&lt;li>&lt;a href="#13-conclusion">13. Conclusion&lt;/a>&lt;/li>
&lt;li>&lt;a href="#14-acknowledgements">14. Acknowledgements&lt;/a>&lt;/li>
&lt;li>&lt;a href="#15-references">15. References&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Keywords:&lt;/strong> agriculture, soil moisture, IoT, machine learning, regression, sklearn&lt;/p>
&lt;h2 id="1-introduction">1. Introduction&lt;/h2>
&lt;p>Maintaining correct soil moisture throughout the plant growing process can result in better yields, and less overall problems with the crop. Water deficiencies or surplus at various stages of growth have different effects, or even negligible effects &lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. It is important to have an idea of how your land consumes and stores water, which could be very different based on the plants being used, and variation of elevation and geography.&lt;/p>
&lt;p>For hundreds of years, farmers have done something similar to this model. The difference is the precision that we can gain by using real data. For the past few hundred years, farmers had to rely on mostly experience and touch to know the moisture of their soil. While many farmers were successful, in the sense that they produced crops, there were ways they could have better optimized their crops to produce better. The water available to the plants is not the only variable that effects yields, but this project seeks to create an accessible model to which farmers can have predicted values of soil moisture without needing to buy and deploy expensive sensors.&lt;/p>
&lt;p>The model created could be used in various ways. The first main use is to be able to monitor what is currently happening in the soil so that changes can be made to correct the issue if there is one. Secondly, a farmer could evaluate historical data and compare it to yields or other results of the harvest and use this analytical information to inform future decisions. For example, a corn farmer might only care about the predicted conditions to make sure that they are within reasonable ranges. A grape farmer in a wine vineyard might use this data, along with other data, to predict the quality of wine or even the recipe of wine that would best used grapes farmed under these conditions. Again, this model is just the starting point of a theoretical complex agricultural data analysis suite.&lt;/p>
&lt;p>This project specifically seeks to see the effect of weather on a particular piece of land in Washington state. This process could be done all over the world to obtain benchmarks. These benchmarks could be a cheap option for a farmer that does not have the funds to support a full study of water usage on their land to use as training data. Instead, they could look for a model that has land that has similar soil and or geographical features, and then use their own weather data to estimate their soil moisture content. A major goal of this project is to create the best tool that is cheap enough for widespread adoption.&lt;/p>
&lt;h2 id="2-background">2. Background&lt;/h2>
&lt;p>Understanding how weather impacts soil moisture is something that has been studied in various ways, all because it is a driving factor in crop success. Multiple studies have sought to apply a deterministic approach to calculating soil moisture based on observational weather data.&lt;/p>
&lt;p>One such study, was motivated by trying to predict dust storms in China, in which soil moisture plays a large role in. This prediction used multiple-linear regression, and focused on predictions that dealt with the top 10 cm of soil. Two key takeaways can be derived from this work that are beneficial for carrying out this project.&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;The influence of precipitation on surface soil moisture content does not last more than 16 days.&amp;rdquo;&lt;/li>
&lt;li>&amp;ldquo;The compound effect of the ratio of precipitation to evaporation, which is nonlinearly summed, can be used to calculate the surface soil moisture content in China&amp;rdquo; &lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/li>
&lt;/ul>
&lt;p>Moving forward, this project will assume that precipitation from the prior 16 days is relevant. In the case that for the specific data being fit, less days are relevant, then their coefficients in the model will likely become small enough to not affect the model. Secondly, soil moisture is influenced by a ratio or precipitation to evaporation. While this project might not seek to evaluate this relationship directly, it will seek to include data that would influence these ratios such as temperature, time of year, and wind speeds.&lt;/p>
&lt;p>Multiple publications have sought to come up with complete hydrological models to determine soil moisture from a variety of factors. These models are generally stochastic in nature and are reliable predictors when many parameters of the model are available. One such cited model requires a minimum or 19 variables or measured coefficients &lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>. The authors of another study note the aforementioned study, as well as other similar studies, and make a point that these methods might not be the best models when it comes to practical applications. Their solution was to create a generalize model that relied mostly on soil moisture as &amp;ldquo;a function of the time-weighted average of previous cumulative rainfall over a period&amp;rdquo; &lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>. Such a model is closer in terms to simplicity and generalization to what is hoped to be accomplished in this project.&lt;/p>
&lt;p>The relationship between soil moisture and weather patterns is one with a rich history of study. Both of these measures affect each other in various ways. Most studies that sought to quantify this relationship were conducted at a time in which large scale sensor arrays could not have been implemented in the field. With the prevalence of IoT and improved sensing technologies, it seems as though there might not be a need to use predictive models for soil moisture, but instead just use sensor data. While this could be true in some applications, a wide array of challenges occur when trying to maintain these sensor arrays. Problems such as charging or replacing batteries, sensor and relay equipment not working if completely buried, but are in the way of farming if mounted above ground, sensors failing, etc. These were real challenges faced by the farm in which the soil moisture data was collected &lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. The objective of this project is to create predictive models based on limited training data so that farmers would not need to deal with sensor arrays indefinitely.&lt;/p>
&lt;h2 id="3-datasets">3. Datasets&lt;/h2>
&lt;p>The first data set comes from NOAA and contains daily summary data in regards to various measurements such as temperature, precipitation, wind speed, etc. For this project, only data that came from the closest station to the field will be used &lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>. In this case, that is the Pullman station at the Pullman-Moscow airport. Below is an image showing the weather data collection location, and the red pin is at the longitude and latitude of one of the sensors in the field. This data is in csv format (see Figure 1).&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-305/main/project/images/distance_map.png" alt="Figure 1">&lt;/p>
&lt;p>&lt;strong>Figure 1:&lt;/strong> Estimated distance from weather reports to the crop fields. Distance is calculated using Google Maps&lt;/p>
&lt;p>The second dataset comes from the USDA. This dataset consists of &amp;ldquo;hourly and daily measurements of volumetric water content, soil temperature, and bulk electrical conductivity, collected at 42 monitoring locations and 5 depths (30, 60, 90, 120, and 150 cm)&amp;rdquo; at a farm in Washington state &lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>. Mainly, the daily temperature and water content are the measurements of interest. There are multiple files that have data that corresponds to what plants are being grown in specific places, and the makeup of the soil at each sensor cite. This auxilary information could be used in later models once the base model has been completed. This data is in tab delimited files.&lt;/p>
&lt;p>Within the data, there are GIS file types that can be imported into Google Maps desktop to visualize the locations of the sensors and other geographical information. Below is an example of the sensor locations plotted on the satellite image (see Figure 2).&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-305/main/project/images/sensor_locations.png" alt="Figure 2">&lt;/p>
&lt;p>&lt;strong>Figure 2:&lt;/strong> Location of sensors within the test field&lt;/p>
&lt;h2 id="4-data-cleaning-and-aggregation">4. Data Cleaning and Aggregation&lt;/h2>
&lt;p>The first step is to get the soil moisture data into a combined format, currently it is in one file per sensor, and there are 42 sensors. See the &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/blob/main/project/code/ml_pipeline.ipynb">ml_pipeline.ipynb&lt;/a> file to see how this was done, specifically the section titled &amp;ldquo;Data Processing&amp;rdquo;. After aggregation, some basic information can be checked about the data. For instance, there is quite a bit of NAs in the data. These NAs are just instances where there was no measurement on that day. There is about 45% NAs in the measurement columns. To further clean the data, any row that has only NAs for the measurements will be removed.&lt;/p>
&lt;p>Next, the weather data needs some small adjustments. This is mostly in the form of removing columns that either are empty or have redundant data such as elevation, which is the same for every row.&lt;/p>
&lt;p>Once the data is sufficiently clean, some choices have to be made on joining the data. The simplest route would be to join the weather measurements directly with the same day the soil measurement, however, the previous days weather is likely to also have an impact on the moisture. As evaluated in section 2 above, it is believed that the prior 16 days weather data is what is needed for a good prediction.&lt;/p>
&lt;h2 id="5-pipeline-for-preprocessing">5. Pipeline for Preprocessing&lt;/h2>
&lt;p>Before feeding the data through a machine learning algorithm, the data needs to be manipulated in such a way that it is ready to be directly fed into an algorithm. This includes joining the two data sets, feature engineering, and other tasks that prepare the data. This will need to be done every time a new dataset is being used, so this must be built in a repeatable way. The machine learning library scikit-learn incorporates something called &amp;ldquo;pipelines&amp;rdquo; that can allow processed to be sequentially done to a dataframe. For purposes of this project two pipelines will be built, one will be used for feature engineering and joining the data, the other will be used to handle preparation of numerical, categorical, and date data. See sections: &amp;ldquo;Data Processing Pipeline&amp;rdquo; in &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/blob/main/project/code/ml_pipeline.ipynb">ml_pipeline.ipynb&lt;/a>.&lt;/p>
&lt;h3 id="51-loading-and-joining-data">5.1 Loading and Joining Data&lt;/h3>
&lt;p>This is the first step of the entire pipeline. This is where both the weather, and the soil moisture data are read in from csv files in their raw format. The soil moisture data is found in many different files, and these all need to be combined. After combining the files, any lines that are full of NAs for the measurements are dropped. Next the weather data is loaded in. Both files have a date field which is the field they will be joined on. To make things consistent, both of these fields need to set be date format.&lt;/p>
&lt;p>When it comes to joining the data, each row should include the moisture content at various depths, as well as the weather information from the past ten days. While this creates a great deal of redundant data, the data is small enough that this is not an issue. Experiments will be done to evaluate just how many days of prior weather data are needed to form accurate results, while trying to minimize the number of the days.&lt;/p>
&lt;h3 id="52-feature-engineering">5.2 Feature Engineering&lt;/h3>
&lt;p>Currently only two features are added, the first is a boolean flag that says whether it rained or not on a certain day. The thought behind this is, that for some days prior to the current measurement, the amount of rain might be needed, but for other days, such as 10 days prior, it might be more important to just know if there was rain or not. This feature is engineered within the pipeline.&lt;/p>
&lt;p>The next feature is a categorical feature that is the month of the year. It isn&amp;rsquo;t very import to know the exact date of a measurement, but the month might be helpful in a model. This simplifies the model by not using date as a predictor, while still being able to capture this potentially important feature.&lt;/p>
&lt;p>An excerpt of the code used to create these two features, this comes from &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/blob/main/project/code/ml_pipeline.ipynb">ml_pipeline.ipynb&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-python" data-lang="python">&lt;span style="color:#000">soil&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;Month&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">pd&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">DatetimeIndex&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">soil&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;Date&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">])&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">month&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#000">i&lt;/span> &lt;span style="color:#204a87;font-weight:bold">in&lt;/span> &lt;span style="color:#204a87">range&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">17&lt;/span>&lt;span style="color:#000;font-weight:bold">):&lt;/span>
&lt;span style="color:#000">col_name&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#39;PRCP_&amp;#39;&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+&lt;/span> &lt;span style="color:#204a87">str&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">i&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#000">rain_y_n_name&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#39;RAIN_Y_N_&amp;#39;&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+&lt;/span> &lt;span style="color:#204a87">str&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">i&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#000">X&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">rain_y_n_name&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">np&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">nan&lt;/span>
&lt;span style="color:#000">X&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">rain_y_n_name&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">loc&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">X&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">col_name&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;gt;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;span style="color:#000">X&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">rain_y_n_name&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">loc&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">X&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">col_name&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">==&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">X&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">rain_y_n_name&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#000">X&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">rain_y_n_name&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">.&lt;/span>&lt;span style="color:#000">astype&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;object&amp;#39;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="53-generic-pipeline">5.3 Generic Pipeline&lt;/h3>
&lt;p>After doing operations that are specific to the current dataset, some built in processors from sklearn are used to make sure the data can be used in a machine learning model. This means that for numerical data types, the pipeline will fill in missing values with 0 instead of leaving them as NaN. Also, the various numerical fields must be standardized, this is important for models such as linear regression so one large variable isn&amp;rsquo;t dominating the model.&lt;/p>
&lt;p>As far as text and categorical features, the imputer will be used to fill in missing data as well. Then a process called one hot encoding will be used to handle the categorical variables so that they can be read into sklearns estimators. Lastly, these two main processes will be put together to make a single pipeline step. Then this pipeline step will be added to a regressor of some sort to create the entire process.&lt;/p>
&lt;h2 id="6-multiple-models-for-multiple-soil-depths">6. Multiple Models for Multiple Soil Depths&lt;/h2>
&lt;p>There are a few different approaches for modeling for this particular problem. The issue is that we have multiple things we would like to predict with the same predictors. It is unlikely that the model that predicts for a depth of 30 cm, would accurately predict for a depth of 150 cm. In order to adjust the models, a separate model will be created for each depth, with that said, the predictors are all the same for each depth, but the trained output is different. To accomplish this, five different datasets were constructed, each one representing a depth. All rows in which the predicted value is not available for that depth were pruned from the dataset.&lt;/p>
&lt;p>In each experiment, there will be 5 different models created. Initially, these 5 models will use the same hyper-parameters for all the depths. It might turn out that all the models will need the same hyper-parameters, or each soil depth could be different. This will be examined through experimentation.&lt;/p>
&lt;h2 id="7-splitting-data-into-train-and-test">7. Splitting Data into Train and Test&lt;/h2>
&lt;p>In order to test any model created, there must be a split between test and training data. This is done by using a function in sklearn. In this case, there are about 76k rows in the data set. For the training data, 80% of the total data will be used, or about 60.8k records. The split is done after shuffling the rows so that it does not just pick the top 80% every time. Lastly the data is split using a stratified method. As we want to have models that take the specific area of the field into account, that means that we need to have the different areas of the field represented equally in both the training and testing dataset. This means that if 10% of the data came from sensor CAF0003, then roughly 10% of the training data will come from CAF0003 as well as 10% of the test data will be from this location.&lt;/p>
&lt;h2 id="8-preliminary-analysis-and-eda">8. Preliminary Analysis and EDA&lt;/h2>
&lt;p>Before building a machine learning model, it is important to get a general idea of how the data looks, to see if any insights can be made right away. The actual visualizations were built using a python package called Altair. This created the visualizations well, but the actual notebook that would contain these images was too large to include in their entirety.&lt;/p>
&lt;p>The first two visualizations (&lt;a href="https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-305/main/project/images/one.png">viz_1&lt;/a>, &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/blob/main/project/images/two.png">viz_2&lt;/a>) are grids that show the entire distribution of measurements across each sensor. The first grid is the volume of water at 30 cm, and the second grid is the water volume at 150 cm. Each chart could be looked at and examined on it&amp;rsquo;s own, but what is most important to note is the variability of the measures from location to location. These different sensors are not that far away, but show that different areas of the farm do retain water in different ways. See Figure 3 for a small section of the grid from the visualization on the sensors at 30cm.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-305/main/project/images/one_small.png" alt="Figure 3">&lt;/p>
&lt;p>&lt;strong>Figure 3:&lt;/strong> Six locations soil moisture level over time at 30 cm depth&lt;/p>
&lt;p>The third and fourth grid shows the temperature at 150 cm, the results are what would logically be expected. The different sensors do not show much variance from location to location.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-305/main/project/images/four_small.png" alt="Figure 4">&lt;/p>
&lt;p>&lt;strong>Figure 4:&lt;/strong> Six locations soil temperature over time at 150 cm depth&lt;/p>
&lt;h2 id="9-initial-model-testing-regressor">9. Initial Model Testing (Regressor)&lt;/h2>
&lt;p>Once the pipelines were setup, the first model could be tested for accuracy. As the output data is continuous in nature, the easiest machine learning algorithm to test to make sure everything is correct, was a linear regression model. It seems fairly likely that a linear regression model would do rather well with this data. The weather is the driving factor in soil moisture in a non-irrigated field, so this test is a litmus test to make sure that the data is good and provide a baseline measurement for future models. The experiment log below shows the returned values from the test that was run. Over the course of experimentation, a log such as this will be kept.&lt;/p>
&lt;p>The results are as follows:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Experiment&lt;/th>
&lt;th>Depth&lt;/th>
&lt;th>Fit_Time&lt;/th>
&lt;th>Pred_Time&lt;/th>
&lt;th>r2_score&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>First Linear Reg&lt;/td>
&lt;td>30cm&lt;/td>
&lt;td>2.029387&lt;/td>
&lt;td>0.169824&lt;/td>
&lt;td>9.16E-01&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>First Linear Reg&lt;/td>
&lt;td>60cm&lt;/td>
&lt;td>2.002373&lt;/td>
&lt;td>0.17377&lt;/td>
&lt;td>-1.42E+15&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>First Linear Reg&lt;/td>
&lt;td>90cm&lt;/td>
&lt;td>2.080393&lt;/td>
&lt;td>0.162992&lt;/td>
&lt;td>9.49E-01&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>First Linear Reg&lt;/td>
&lt;td>120cm&lt;/td>
&lt;td>2.299457&lt;/td>
&lt;td>0.18056&lt;/td>
&lt;td>9.46E-01&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>First Linear Reg&lt;/td>
&lt;td>150cm&lt;/td>
&lt;td>2.573193&lt;/td>
&lt;td>0.186042&lt;/td>
&lt;td>9.43E-01&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Figure 5:&lt;/strong> Baseline experiment results&lt;/p>
&lt;p>These results show that the data is pretty well correlated and that there is reason to believe that we could predict soil moisture from weather alone. Although an r^2 of around 0.916-0.949 are pretty good, with such highly related predictors, there is definitely room for model improvement. Also for a depth of 60 cm, something is not predicting correctly and is resulting in a small negative r^2&lt;/p>
&lt;h2 id="10-classifier-vs-regressor">10. Classifier vs. Regressor&lt;/h2>
&lt;p>While the output is continuous, there is an argument to use a categorical classifier model. For a specific plant, an optimal moisture range could be studied. For examples sake, the range could be 0.2-0.4 units. Then it would not matter if the soil is 0.2 or 0.3, both would be in the acceptable range. With this in mind, certain levels could be created to alert the farmer of which category they could be experiencing. For example there might be five levels: too dry, acceptable dryness, optimal, acceptable wetness, and too wet. The training data could be adjusted to fit into these categories.&lt;/p>
&lt;p>Code to create a categorical variable for each of the depth measurements can be found in the section &amp;ldquo;Make Classifier Label&amp;rdquo; in the file: &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/blob/main/project/code/ml_pipeline.ipynb">ml_pipeline.ipynb&lt;/a>.&lt;/p>
&lt;p>In the end, the decision to not use classifier methods was made. After using a regressor, the output could be converted to a categorical feature if the user or application so desired this. As our output is continuous in nature, precision would be lost.&lt;/p>
&lt;h2 id="11-various-other-linear-regression-model-experiments">11. Various Other Linear Regression Model Experiments&lt;/h2>
&lt;p>The next set of experiments came up with the results in the following table. This was a test to see if baseline Lasso or Ridge Regression would improve on the basic linear regression model. Results and code for this portion can be found in &lt;a href="https://github.com/cybertraining-dsc/fa20-523-305/blob/main/project/code/ml_pipeline.ipynb">ml_pipeline.ipynb&lt;/a> under the &amp;ldquo;Linear Regression Tests&amp;rdquo; section.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Experiment&lt;/th>
&lt;th>Depth&lt;/th>
&lt;th>Fit_Time&lt;/th>
&lt;th>Pred_Time&lt;/th>
&lt;th>r2_score&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Ridge Reg, Alpha = 1&lt;/td>
&lt;td>30cm&lt;/td>
&lt;td>1.321553&lt;/td>
&lt;td>0.173714&lt;/td>
&lt;td>0.916211&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg, Alpha = 1&lt;/td>
&lt;td>60cm&lt;/td>
&lt;td>1.29167&lt;/td>
&lt;td>0.187392&lt;/td>
&lt;td>0.942757&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg, Alpha = 1&lt;/td>
&lt;td>90cm&lt;/td>
&lt;td>1.393526&lt;/td>
&lt;td>0.197152&lt;/td>
&lt;td>0.94879&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg, Alpha = 1&lt;/td>
&lt;td>120cm&lt;/td>
&lt;td>1.307926&lt;/td>
&lt;td>0.176656&lt;/td>
&lt;td>0.946032&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg, Alpha = 1&lt;/td>
&lt;td>150cm&lt;/td>
&lt;td>1.33738&lt;/td>
&lt;td>0.179585&lt;/td>
&lt;td>0.94332&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Lasso Reg, Alpha = 1&lt;/td>
&lt;td>30cm&lt;/td>
&lt;td>1.45102&lt;/td>
&lt;td>0.170752&lt;/td>
&lt;td>-0.00018&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Lasso Reg, Alpha = 1&lt;/td>
&lt;td>60cm&lt;/td>
&lt;td>1.419546&lt;/td>
&lt;td>0.174177&lt;/td>
&lt;td>-4.6E-05&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Lasso Reg, Alpha = 1&lt;/td>
&lt;td>90cm&lt;/td>
&lt;td>1.4632&lt;/td>
&lt;td>0.176657&lt;/td>
&lt;td>-5.7E-06&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Lasso Reg, Alpha = 1&lt;/td>
&lt;td>120cm&lt;/td>
&lt;td>1.553091&lt;/td>
&lt;td>0.182349&lt;/td>
&lt;td>-1.1E-06&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Lasso Reg, Alpha = 1&lt;/td>
&lt;td>150cm&lt;/td>
&lt;td>1.437419&lt;/td>
&lt;td>0.163967&lt;/td>
&lt;td>-0.00018&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg - GSCV&lt;/td>
&lt;td>30cm&lt;/td>
&lt;td>3.914718&lt;/td>
&lt;td>0.203007&lt;/td>
&lt;td>0.916235&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg - GSCV&lt;/td>
&lt;td>60cm&lt;/td>
&lt;td>3.726651&lt;/td>
&lt;td>0.172752&lt;/td>
&lt;td>0.942757&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg - GSCV&lt;/td>
&lt;td>90cm&lt;/td>
&lt;td>4.135154&lt;/td>
&lt;td>0.200589&lt;/td>
&lt;td>0.948796&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg - GSCV&lt;/td>
&lt;td>120cm&lt;/td>
&lt;td>4.03203&lt;/td>
&lt;td>0.193512&lt;/td>
&lt;td>0.946032&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Ridge Reg - GSCV&lt;/td>
&lt;td>150cm&lt;/td>
&lt;td>4.361977&lt;/td>
&lt;td>0.191296&lt;/td>
&lt;td>0.943328&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Figure 6:&lt;/strong> Further Linear Regression Experiment Results&lt;/p>
&lt;p>For the first two experiments, an alpha of 1 was used for both ridge and lasso regression. The third experiment used a special regressor that uses cross validation to try to find the best alpha value and then fit the model based on that. The best alpha value seemed to not have much effect at all on the results. Still the ridge regression so far was the best performing model.&lt;/p>
&lt;h2 id="12-other-models">12. Other Models&lt;/h2>
&lt;p>While there were great results in the different linear regression models, other models should be evaluated to make sure that something is not missed. Three models were chosen to check, Stochastic Gradient Descent, Support Vector Machine, and Random Forest. All of these models were tested with default parameters and their results are shown below in Figure 7, and the code can be found in the section called &amp;ldquo;Other Regressors Tests&amp;rdquo;.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Experiment&lt;/th>
&lt;th>Depth&lt;/th>
&lt;th>Fit_Time&lt;/th>
&lt;th>Pred_Time&lt;/th>
&lt;th>r2_score&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Random Forest&lt;/td>
&lt;td>30cm&lt;/td>
&lt;td>60.06952&lt;/td>
&lt;td>0.250543&lt;/td>
&lt;td>0.977118&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Random Forest&lt;/td>
&lt;td>60cm&lt;/td>
&lt;td>62.17435&lt;/td>
&lt;td>0.216641&lt;/td>
&lt;td>0.989113&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Random Forest&lt;/td>
&lt;td>90cm&lt;/td>
&lt;td>62.29475&lt;/td>
&lt;td>0.243051&lt;/td>
&lt;td>0.99158&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Random Forest&lt;/td>
&lt;td>120cm&lt;/td>
&lt;td>64.48227&lt;/td>
&lt;td>0.256666&lt;/td>
&lt;td>0.991274&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Random Forest&lt;/td>
&lt;td>150cm&lt;/td>
&lt;td>68.47001&lt;/td>
&lt;td>0.240149&lt;/td>
&lt;td>0.991748&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SVM&lt;/td>
&lt;td>30cm&lt;/td>
&lt;td>38.83822&lt;/td>
&lt;td>5.712513&lt;/td>
&lt;td>0.676934&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SVM&lt;/td>
&lt;td>60cm&lt;/td>
&lt;td>106.2816&lt;/td>
&lt;td>7.897556&lt;/td>
&lt;td>0.766008&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SVM&lt;/td>
&lt;td>90cm&lt;/td>
&lt;td>102.9438&lt;/td>
&lt;td>7.763206&lt;/td>
&lt;td>0.788833&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SVM&lt;/td>
&lt;td>120cm&lt;/td>
&lt;td>79.76476&lt;/td>
&lt;td>6.985236&lt;/td>
&lt;td>0.760895&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SVM&lt;/td>
&lt;td>150cm&lt;/td>
&lt;td>96.46352&lt;/td>
&lt;td>7.548365&lt;/td>
&lt;td>0.760936&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SGD&lt;/td>
&lt;td>30cm&lt;/td>
&lt;td>1.382992&lt;/td>
&lt;td>0.171777&lt;/td>
&lt;td>0.89019&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SGD&lt;/td>
&lt;td>60cm&lt;/td>
&lt;td>1.392753&lt;/td>
&lt;td>0.15128&lt;/td>
&lt;td>0.931394&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SGD&lt;/td>
&lt;td>90cm&lt;/td>
&lt;td>1.399587&lt;/td>
&lt;td>0.142493&lt;/td>
&lt;td>0.941092&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SGD&lt;/td>
&lt;td>120cm&lt;/td>
&lt;td>1.438626&lt;/td>
&lt;td>0.150302&lt;/td>
&lt;td>0.936692&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SGD&lt;/td>
&lt;td>150cm&lt;/td>
&lt;td>1.403488&lt;/td>
&lt;td>0.14933&lt;/td>
&lt;td>0.92957&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Figure 7:&lt;/strong> Further Linear Regression Experiment Results&lt;/p>
&lt;p>The random forest regressor performed amazingly in predicting the soil moisture. While the lower depths of soil did perform better than the depth of 30 cm. As random forests performed so well out of the box, some attempts were made to tune the hyperparameters, but most experiments turned out to be computationally expensive.&lt;/p>
&lt;h2 id="13-conclusion">13. Conclusion&lt;/h2>
&lt;p>The end results of all experimentation was a process in which two datasets could be joined and fed into a model to predict the soil moisture with great accuracy, an r^2 score of between 0.977 and 0.991 depending on the depth using a Random Forest Regressor with default settings. This process could be a repeatable process in which a farmer contracts a company to gather training data on their land specifically for a growing season. As the collection of the sensor data could be cumbersome and expensive to deal with as a farmer, so this is an alternative that is cheaper and still gives nearly the same results as having sensors constantly running. Alternatively, this process could be a subprocess in a larger suite of software that farmers could use for predictive analysis or even to have data on soil moisture from a grow season to use in post season analysis of their crop produced. As long as large scale AI programs are still expensive and cumbersome for farmers to deal with, there will be a low rate of adoption. This project has shown that a solution for large scale soil moisture prediction software could be done with relatively low computational cost.&lt;/p>
&lt;h2 id="14-acknowledgements">14. Acknowledgements&lt;/h2>
&lt;p>The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the &lt;em>FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em> course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article.&lt;/p>
&lt;h2 id="15-references">15. References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>O. Denmead and R. Shaw, &amp;ldquo;The Effects of Soil Moisture Stress at Different Stages of Growth on the Development and Yield of Corn 1&amp;rdquo;, Agronomy Journal, vol. 52, no. 5, pp. 272-274, 1960. Available: 10.2134/agronj1960.00021962005200050010x. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>K. Shang, S. Wang, Y. Ma, Z. Zhou, J. Wang, H. Liu and Y. Wang, &amp;ldquo;A scheme for calculating soil moisture content by using routine weather data&amp;rdquo;, Atmospheric Chemistry and Physics, vol. 7, no. 19, pp. 5197-5206, 2007 [Online]. Available: &lt;a href="https://hal.archives-ouvertes.fr/hal-00302825/document">https://hal.archives-ouvertes.fr/hal-00302825/document&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>W. Capehart and T. Carlson, &amp;ldquo;Estimating near-surface soil moisture availability using a meteorologically driven soil-water profile model&amp;rdquo;, Journal of Hydrology, vol. 160, no. 1-4, pp. 1-20, 1994 [Online]. Available: &lt;a href="https://tinyurl.com/yxjyuy5x">https://tinyurl.com/yxjyuy5x&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>F. Pan, C. Peters-Lidard and M. Sale, &amp;ldquo;An analytical method for predicting surface soil moisture from rainfall observations&amp;rdquo;, Water Resources Research, vol. 39, no. 11, 2003 [Online]. Available: &lt;a href="https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2003WR002142">https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2003WR002142&lt;/a>. [Accessed: 08- Nov- 2020] &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>C. Gasch, D. Brown, C. Campbell, D. Cobos, E. Brooks, M. Chahal and M. Poggio, &amp;ldquo;A Field-Scale Sensor Network Data Set for Monitoring and Modeling the Spatial and Temporal Variation of Soil Water Content in a Dryland Agricultural Field&amp;rdquo;, Water Resources Research, vol. 53, no. 12, pp. 10878-10887, 2017 [Online]. Available: &lt;a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017WR021307">https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017WR021307&lt;/a>. [Accessed: 08- Nov- 2020] &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>N. (NCEI), &amp;ldquo;Climate Data Online (CDO) - The National Climatic Data Center&amp;rsquo;s (NCDC) Climate Data Online (CDO) provides free access to NCDC&amp;rsquo;s archive of historical weather and climate data in addition to station history information. | National Climatic Data Center (NCDC)&amp;rdquo;, Ncdc.noaa.gov, 2020. [Online]. Available: &lt;a href="https://www.ncdc.noaa.gov/cdo-web/">https://www.ncdc.noaa.gov/cdo-web/&lt;/a>. [Accessed: 19- Oct- 2020]. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>&amp;ldquo;Data from: A field-scale sensor network data set for monitoring and modeling the spatial and temporal variation of soil moisture in a dryland agricultural field&amp;rdquo;, USDA: Ag Data Commons, 2020. [Online]. Available: &lt;a href="https://data.nal.usda.gov/dataset/data-field-scale-sensor-network-data-set-monitoring-and-modeling-spatial-and-temporal-variation-soil-moisture-dryland-agricultural-field">https://data.nal.usda.gov/dataset/data-field-scale-sensor-network-data-set-monitoring-and-modeling-spatial-and-temporal-variation-soil-moisture-dryland-agricultural-field&lt;/a>. [Accessed: 19- Oct- 2020]. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item></channel></rss>